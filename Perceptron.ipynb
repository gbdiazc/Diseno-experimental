{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b37975-9a30-44e2-8aa4-0113acb05679",
   "metadata": {},
   "source": [
    "# Perceptrón: Introducción y Fundamentos\n",
    "\n",
    "El **perceptrón** es uno de los modelos más sencillos y fundamentales en el campo del aprendizaje automático y redes neuronales artificiales. Fue propuesto por **Frank Rosenblatt en 1958**, inspirado en el modelo de neuronas de **McCulloch y Pitts** (1943), quienes intentaron modelar computacionalmente el comportamiento de las neuronas biológicas.\n",
    "\n",
    "\n",
    "\n",
    "## ¿Qué es el perceptrón?\n",
    "\n",
    "Es un modelo matemático de una **neurona artificial** que recibe múltiples entradas (features), las **pesa**, las **suma**, y pasa el resultado por una **función de activación** (normalmente una función escalón). El resultado es una salida binaria, $0$ o $1$.\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://github.com/gbdiazc/Diseno-experimental/raw/main/Images/neurona.png\" alt=\"Neurona\" width=\"400\">\n",
    "</div>\n",
    "\n",
    "\n",
    "Se utiliza principalmente para **clasificación binaria**, en problemas donde las clases pueden separarse con una línea recta (2D), un plano (3D) o un hiperplano (más dimensiones). \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Motivación\n",
    "\n",
    "El perceptrón intenta **emular el proceso de decisión de una neurona biológica**, donde las entradas (señales sinápticas) se combinan para decidir si la neurona dispara o no. En su versión computacional:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Nombre</th>\n",
    "    <th>Símbolo</th>\n",
    "    <th>Descripción</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Entradas</td>\n",
    "    <td>$\\mathbf{x}$</td>\n",
    "    <td>Representan las características de los datos</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Pesos</td>\n",
    "    <td>$\\mathbf{w}$</td>\n",
    "    <td>Determinan la importancia de cada entrada</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Suma ponderada + sesgo</td>\n",
    "    <td>$z$</td>\n",
    "    <td>Resultado de la combinación lineal de entradas y pesos más un sesgo</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Función de activación</td>\n",
    "    <td>$\\phi(z)$</td>\n",
    "    <td>Decide si la neurona “dispara” o no, aplicando una regla de decisión</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Resultado binario</td>\n",
    "    <td>$\\hat{y}$</td>\n",
    "    <td>Salida del perceptrón; indica la clase predicha (0 o 1)</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"https://github.com/gbdiazc/Diseno-experimental/raw/main/Images/perceptron.png\" alt=\"Perceptron\" width=\"400\">\n",
    "</div>\n",
    "\n",
    "El perceptrón es un **modelo lineal de clasificación**: traza un hiperplano en el espacio de características para separar dos clases. Funciona bien **solo cuando los datos son linealmente separables**. Su simplicidad lo hace un buen punto de partida para introducir redes neuronales más complejas.\n",
    "\n",
    "El entrenamiento del perceptrón consiste en **ajustar los pesos** automáticamente a partir de ejemplos etiquetados, corrigiendo los errores de predicción mediante un algoritmo iterativo.\n",
    "\n",
    "## Formulación matemática\n",
    "\n",
    "Dado un vector de entrada $\\mathbf{x} = (x_1, x_2, \\dots, x_n)$ y un vector de pesos $\\mathbf{w} = (w_1, w_2, \\dots, w_n)$, el perceptrón calcula:\n",
    "\n",
    "### Suma ponderada:\n",
    "$$\n",
    "z = \\mathbf{w} \\cdot \\mathbf{x} + b = \\sum_{i=1}^{n} w_i x_i + b\n",
    "$$\n",
    "\n",
    "### Función de activación (escalón):\n",
    "La función de activación $\\phi(z)$ convierte la salida continua $z$ en una predicción discreta. En el perceptrón clásico, se utiliza una función escalón (o función umbral):\n",
    "\n",
    "$$\n",
    "\\phi(z) = \n",
    "\\begin{cases}\n",
    "1 & \\text{si } z > 0 \\\\\n",
    "0 & \\text{si } z \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "El resultado final es:\n",
    "$$\n",
    "\\hat{y} = \\phi(z)\n",
    "$$\n",
    "donde $\\hat{y}$ es la clase predicha (0 o 1).).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823a6402-9c13-47f6-8149-3928444dc19f",
   "metadata": {},
   "source": [
    "## Algoritmo de entrenamiento del perceptrón (Regla de Rosenblatt)\n",
    "\n",
    "El objetivo del **algoritmo de entrenamiento del perceptrón** es ajustar los pesos del modelo para que pueda clasificar correctamente las muestras del conjunto de entrenamiento. Este procedimiento es un ejemplo de **aprendizaje supervisado**, ya que el modelo aprende comparando su salida con la etiqueta verdadera de cada muestra.\n",
    "\n",
    "El objetivo del entrenamiento es encontrar un vector de pesos $\\mathbf{w}$ y un sesgo $b$ que permitan al perceptrón clasificar correctamente los datos de entrenamiento. Se trata de un algoritmo **supervisado** porque usa ejemplos con sus etiquetas verdaderas.\n",
    "\n",
    "El aprendizaje se basa en actualizar los pesos **cuando la predicción es incorrecta**, es decir, cuando $\\hat{y} \\ne y$.\n",
    "\n",
    "\n",
    "### Función de activación\n",
    "\n",
    "El perceptrón utiliza una función de activación **escalón** (también llamada función signum) que transforma la salida continua de la combinación lineal en una clase binaria. En su forma más común:\n",
    "\n",
    "$$\n",
    "\\phi(z) = \n",
    "\\begin{cases}\n",
    "1 & \\text{si } \\mathbf{w} \\cdot \\mathbf{x} + b > \\theta \\\\\n",
    "0 \\; \\text{o } -1 & \\text{si } \\mathbf{w} \\cdot \\mathbf{x} + b \\leq \\theta\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Para fines prácticos, se suele usar $\\theta = 0$ y representar la salida con $1$ o $-1$:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\text{sign}(\\mathbf{w} \\cdot \\mathbf{x} + b) = \n",
    "\\begin{cases}\n",
    "1 & \\text{si } \\mathbf{w} \\cdot \\mathbf{x} + b > 0 \\\\\n",
    "-1 & \\text{si } \\mathbf{w} \\cdot \\mathbf{x} + b \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### Regla de actualización de pesos\n",
    "\n",
    "Cuando hay un error ($e \\ne 0$), se actualizan los pesos y el sesgo usando:\n",
    "\n",
    "$$\n",
    "w_j \\leftarrow w_j + \\eta \\cdot e \\cdot x_j, \\quad \\text{para cada } j = 1, 2, \\dots, n\n",
    "$$\n",
    "\n",
    "$$\n",
    "b \\leftarrow b + \\eta \\cdot e\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_j^{(i+1)}  = w_j^{(i)} + \\eta \\cdot e \\cdot x_j, \\quad \\text{para cada } j = 1, 2, \\dots, n\n",
    "$$\n",
    "\n",
    "$$\n",
    "b^{(i+1)} = b^{(i)} + \\eta \\cdot e\n",
    "$$\n",
    "\n",
    "Esta regla mueve el hiperplano de decisión en la dirección que reduce el error.\n",
    "\n",
    "\n",
    "### Algoritmo \n",
    "\n",
    "1. **Inicialización**:  \n",
    "   Asignar valores pequeños (por ejemplo, aleatorios o ceros) a los pesos $\\mathbf{w}$ y al sesgo $b$.\n",
    "\n",
    "2. **Para cada época** (recorrido completo por los datos):  \n",
    "   Para cada muestra $(\\mathbf{x}, y)$ del conjunto de entrenamiento:\n",
    "\n",
    "   a. Calcular la salida lineal:\n",
    "   $$\n",
    "   z = \\mathbf{w} \\cdot \\mathbf{x} + b\n",
    "   $$\n",
    "\n",
    "   b. Aplicar la función de activación:\n",
    "   $$\n",
    "   \\hat{y} = \\phi(z) = \n",
    "   \\begin{cases}\n",
    "   1 & \\text{si } z > 0 \\\\\n",
    "   0 & \\text{si } z \\leq 0\n",
    "   \\end{cases}\n",
    "   $$\n",
    "\n",
    "   c. Calcular el error:\n",
    "   $$\n",
    "   e = y - \\hat{y}\n",
    "   $$\n",
    "\n",
    "   d. Actualizar pesos y sesgo (solo si $e \\ne 0$):\n",
    "   $$\n",
    "   w_j^{(i+1)}  = w_j^{(i)} + \\eta \\cdot e \\cdot x_j, \\quad \\text{para cada } j = 1, 2, \\dots, n\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   b^{(i+1)} = b^{(i)} + \\eta \\cdot e\n",
    "   $$\n",
    "\n",
    "3. **Repetir** el paso 2 hasta que no haya errores o se alcance el número máximo de épocas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d45220-8c27-4bb1-aa97-838c0c37e9b7",
   "metadata": {},
   "source": [
    "## Ejemplo\n",
    "\n",
    "Se tienen los siguientes datos (1-4) dados por $(x_1,x_2)$, con sus respectivas clasificaciones ${y}$:\n",
    "\n",
    "| Dato | $x_1$ | $x_2$ | ${y}$ |\n",
    "|------|------|------|-----|\n",
    "| 1    | 0    | 0    | 1   |\n",
    "| 2    | 0    | 1    | 1   |\n",
    "| 3    | 1    | 0    | 1   |\n",
    "| 4    | 1    | 1    | 0   |\n",
    "\n",
    "\n",
    "Es decir, tenemos:\n",
    "\n",
    "$$ $$ $$  x_{1} = \\begin{bmatrix} x_{11}\\\\x_{21}\\\\x_{31}\\\\x_{41} \\end{bmatrix} = \\begin{bmatrix} 0\\\\0\\\\1\\\\1 \\end{bmatrix}, \\quad x_{2} = \\begin{bmatrix} x_{12}\\\\x_{22}\\\\x_{32}\\\\x_{42} \\end{bmatrix} = \\begin{bmatrix} 0\\\\1\\\\0\\\\1 \\end{bmatrix}, \\quad  \\hat{y} = \\begin{bmatrix} \\hat{y}_{1}\\\\\\hat{y}_{2}\\\\\\hat{y}_{3}\\\\\\hat{y}_{4} \\end{bmatrix} = \\begin{bmatrix} 1\\\\1\\\\1\\\\0 \\end{bmatrix},  $$\n",
    "\n",
    "Tomamos como vector inicial $x_0$ .\n",
    "\n",
    "$$\n",
    "\\quad  x_0 = \\begin{bmatrix} x_{10}\\\\x_{20}\\\\x_{30}\\\\x_{40} \\end{bmatrix} = \\begin{bmatrix} 1\\\\1\\\\1\\\\1 \\end{bmatrix}.$$\n",
    "\n",
    "\n",
    "a siguiente muestra de entrenamiento $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280e8be3-9848-40d4-a2d6-08ae40ea0508",
   "metadata": {},
   "source": [
    "## Algoritmo de entrenamiento\n",
    "\n",
    "## Iteración 1 (Epoch 1)\n",
    "\n",
    "## Paso 1: Inicialización\n",
    "\n",
    "- Pesos iniciales:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}^0 = \\begin{bmatrix} w_0^0 \\\\ w_1^0 \\\\ w_2^0 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- Umbral (theta): $\\theta = 0$\n",
    "\n",
    "- Tasa de aprendizaje: $\\eta = 0.1$\n",
    "\n",
    "- Conjunto de entrenamiento:\n",
    "\n",
    "| Patrón $x_i$ | $\\mathbf{x}_i$         | $y_i$ |\n",
    "|--------------|------------------------|-------|\n",
    "| $x_1$        | $\\begin{bmatrix}1 \\\\ 0 \\\\ 0\\end{bmatrix}$ | 1     |\n",
    "| $x_2$        | $\\begin{bmatrix}1 \\\\ 0 \\\\ 1\\end{bmatrix}$ | 1     |\n",
    "| $x_3$        | $\\begin{bmatrix}1 \\\\ 1 \\\\ 0\\end{bmatrix}$ | 1     |\n",
    "| $x_4$        | $\\begin{bmatrix}1 \\\\ 1 \\\\ 1\\end{bmatrix}$ | 0     |\n",
    "\n",
    "## Paso 2: Salida lineal $z_i = \\mathbf{w} \\cdot \\mathbf{x}_i$\n",
    "\n",
    "### Cálculo vectorial explícito:\n",
    "\n",
    "### Para $x_1 = \\begin{bmatrix}1 \\\\ 0 \\\\ 0\\end{bmatrix}$:\n",
    "\n",
    "$$\n",
    "z_1 = \\mathbf{w}^0 \\cdot \\mathbf{x}_1 = \n",
    "\\begin{bmatrix}0 & 0 & 0\\end{bmatrix} \\cdot \\begin{bmatrix}1 \\\\ 0 \\\\ 0\\end{bmatrix} = 0 \\times 1 + 0 \\times 0 + 0 \\times 0 = 0\n",
    "$$\n",
    "\n",
    "### Para $x_2 = \\begin{bmatrix}1 \\\\ 0 \\\\ 1\\end{bmatrix}$:\n",
    "\n",
    "$$\n",
    "z_2 = \\mathbf{w}^0 \\cdot \\mathbf{x}_2 = \n",
    "\\begin{bmatrix}0 & 0 & 0\\end{bmatrix} \\cdot \\begin{bmatrix}1 \\\\ 0 \\\\ 1\\end{bmatrix} = 0 \\times 1 + 0 \\times 0 + 0 \\times 1 = 0\n",
    "$$\n",
    "\n",
    "### Para $x_3 = \\begin{bmatrix}1 \\\\ 1 \\\\ 0\\end{bmatrix}$:\n",
    "\n",
    "$$\n",
    "z_3 = \\mathbf{w}^0 \\cdot \\mathbf{x}_3 = \n",
    "\\begin{bmatrix}0 & 0 & 0\\end{bmatrix} \\cdot \\begin{bmatrix}1 \\\\ 1 \\\\ 0\\end{bmatrix} = 0 \\times 1 + 0 \\times 1 + 0 \\times 0 = 0\n",
    "$$\n",
    "\n",
    "### Para $x_4 = \\begin{bmatrix}1 \\\\ 1 \\\\ 1\\end{bmatrix}$:\n",
    "\n",
    "$$\n",
    "z_4 = \\mathbf{w}^0 \\cdot \\mathbf{x}_4 = \n",
    "\\begin{bmatrix}0 & 0 & 0\\end{bmatrix} \\cdot \\begin{bmatrix}1 \\\\ 1 \\\\ 1\\end{bmatrix} = 0 \\times 1 + 0 \\times 1 + 0 \\times 1 = 0\n",
    "$$\n",
    "\n",
    "## Paso 3: Aplicar función de activación\n",
    "\n",
    "Función escalón:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\phi(z_i) = \\begin{cases}\n",
    "1 & \\text{si } z_i > \\theta \\\\\n",
    "0 & \\text{si } z_i \\leq \\theta\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Dado que todos los $z_i = 0$ y $\\theta = 0$, entonces:\n",
    "\n",
    "- $\\hat{y}_1 = 0$\n",
    "- $\\hat{y}_2 = 0$\n",
    "- $\\hat{y}_3 = 0$\n",
    "- $\\hat{y}_4 = 0$\n",
    "\n",
    "## Paso 4: Comparar salida predicha vs esperada\n",
    "\n",
    "| Patrón $x_i$ | $y_i$ (esperado) | $\\hat{y}_i$ (predicho) | Error $e_i = y_i - \\hat{y}_i$ |\n",
    "|--------------|------------------|--------------------------|------------------------------|\n",
    "| $x_1$        | 1                | 0                        | 1                            |\n",
    "| $x_2$        | 1                | 0                        | 1                            |\n",
    "| $x_3$        | 1                | 0                        | 1                            |\n",
    "| $x_4$        | 0                | 0                        | 0                            |\n",
    "\n",
    "## Paso 5: Actualización de pesos (por cada patrón con error)\n",
    "\n",
    "Vamos a actualizar los pesos para cada patrón con error, secuencialmente.\n",
    "\n",
    "### Para $x_1$ con $e_1 = 1$:\n",
    "\n",
    "$$\n",
    "w_j^{1} = w_j^{0} + \\eta \\cdot e_1 \\cdot x_{1j}\n",
    "$$\n",
    "\n",
    "- $w_0^{1} = 0 + 0.1 \\times 1 \\times 1 = 0.1$\n",
    "- $w_1^{1} = 0 + 0.1 \\times 1 \\times 0 = 0$\n",
    "- $w_2^{1} = 0 + 0.1 \\times 1 \\times 0 = 0$\n",
    "\n",
    "Pesos actualizados:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}^1 = \\begin{bmatrix} 0.1 \\\\ 0 \\\\ 0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### Para $x_2$ con $e_2 = 1$:\n",
    "\n",
    "$$\n",
    "w_j^{2} = w_j^{1} + \\eta \\cdot e_2 \\cdot x_{2j}\n",
    "$$\n",
    "\n",
    "- $w_0^{2} = 0.1 + 0.1 \\times 1 \\times 1 = 0.2$\n",
    "- $w_1^{2} = 0 + 0.1 \\times 1 \\times 0 = 0$\n",
    "- $w_2^{2} = 0 + 0.1 \\times 1 \\times 1 = 0.1$\n",
    "\n",
    "Pesos actualizados:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}^2 = \\begin{bmatrix} 0.2 \\\\ 0 \\\\ 0.1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### Para $x_3$ con $e_3 = 1$:\n",
    "\n",
    "$$\n",
    "w_j^{3} = w_j^{2} + \\eta \\cdot e_3 \\cdot x_{3j}\n",
    "$$\n",
    "\n",
    "- $w_0^{3} = 0.2 + 0.1 \\times 1 \\times 1 = 0.3$\n",
    "- $w_1^{3} = 0 + 0.1 \\times 1 \\times 1 = 0.1$\n",
    "- $w_2^{3} = 0.1 + 0.1 \\times 1 \\times 0 = 0.1$\n",
    "\n",
    "Pesos actualizados:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}^3 = \\begin{bmatrix} 0.3 \\\\ 0.1 \\\\ 0.1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### Para $x_4$ con $e_4 = 0$ no se actualiza.\n",
    "\n",
    "## Resumen de la Iteración 1\n",
    "\n",
    "| Paso       | $\\mathbf{w}^0$    Inicial            | $\\hat{\\mathbf{y}}$      | $\\mathbf{y}$       | Error           | $\\mathbf{w}^3$    Final| \n",
    "|------------|--------------------------------------|-------------------------|--------------------|-----------------|------------------------|\n",
    "|            | $\\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$ | $[0,\\ 0,\\ 0,\\ 0]$         | $[1,\\ 1,\\ 1,\\ 0]$  | $[1,\\ 1,\\ 1,\\ 0]$ |$\\begin{bmatrix} 0.3 \\\\ 0.1 \\\\ 0.1 \\end{bmatrix}$ |\n",
    "\n",
    "$$\r\n",
    "ECM = \\frac{1}{4} (1^2 + 1^2 + 1^2 + 0^2) = \\frac{3}{4} = 0.75\r\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f41d9e2-ab85-4dca-b47c-27a75f4a4f30",
   "metadata": {},
   "source": [
    "## Iteración 2 (Epoch 2)\n",
    "\n",
    "\n",
    "### Paso 1: Pesos iniciales para esta iteración\n",
    "\n",
    "$$\n",
    "\\mathbf{w}^1 = \\begin{bmatrix} 0.0 \\\\ 0.0 \\\\ 0.0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "### Paso 2: Cálculo de la salida lineal $z_i = \\mathbf{w}^1 \\cdot \\mathbf{x}_i$\n",
    "\n",
    "Para cada patrón $\\mathbf{x}_i$:\n",
    "\n",
    "- Para $\\mathbf{x}_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}$:\n",
    "\n",
    "$$\n",
    "z_1 = \\begin{bmatrix} 0 & 0 & 0 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix} = 0\n",
    "$$\n",
    "\n",
    "- Para $\\mathbf{x}_2 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\end{bmatrix}$:\n",
    "\n",
    "$$\n",
    "z_2 = \\begin{bmatrix} 0 & 0 & 0 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\end{bmatrix} = 0\n",
    "$$\n",
    "\n",
    "- Para $\\mathbf{x}_3 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix}$:\n",
    "\n",
    "$$\n",
    "z_3 = \\begin{bmatrix} 0 & 0 & 0 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix} = 0\n",
    "$$\n",
    "\n",
    "- Para $\\mathbf{x}_4 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix}$:\n",
    "\n",
    "$$\n",
    "z_4 = \\begin{bmatrix} 0 & 0 & 0 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix} = 0\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### Paso 3: Aplicar función escalón con umbral $\\theta = 0$\n",
    "\n",
    "La función de activación es:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\phi(z_i) = \\begin{cases}\n",
    "1 & \\text{si } z_i > 0 \\\\\n",
    "0 & \\text{si } z_i \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Como todos los $z_i = 0$, entonces:\n",
    "\n",
    "$$\n",
    "\\hat{y}_1 = 0, \\quad \\hat{y}_2 = 0, \\quad \\hat{y}_3 = 0, \\quad \\hat{y}_4 = 0\n",
    "$$\n",
    "\n",
    "\n",
    "### Paso 4: Comparación de salida predicha vs esperada\n",
    "\n",
    "| Patrón $\\mathbf{x}_i$ | Salida esperada $y_i$ | Salida predicha $\\hat{y}_i$ | Error $e_i = y_i - \\hat{y}_i$ |\n",
    "|-----------------------|-----------------------|-----------------------------|-------------------------------|\n",
    "| $\\mathbf{x}_1$         | 1                     | 0                           | 1                             |\n",
    "| $\\mathbf{x}_2$         | 1                     | 0                           | 1                             |\n",
    "| $\\mathbf{x}_3$         | 1                     | 0                           | 1                             |\n",
    "| $\\mathbf{x}_4$         | 0                     | 0                           | 0                             |\n",
    "\n",
    "\n",
    "### Paso 5: Actualización de pesos\n",
    "\n",
    "La regla de actualización es:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}^{(t+1)} = \\mathbf{w}^{(t)} + \\eta \\, e_i \\, \\mathbf{x}_i\n",
    "$$\n",
    "\n",
    "con tasa de aprendizaje $\\eta = 0.1$.\n",
    "\n",
    "\n",
    "\n",
    "Actualizamos los pesos para los patrones con error distinto de cero:\n",
    "\n",
    "- Para $\\mathbf{x}_1$ (error = 1):\n",
    "\n",
    "$$\n",
    "\\mathbf{w}^1 = \\begin{bmatrix}0 \\\\ 0 \\\\ 0\\end{bmatrix} + 0.1 \\times 1 \\times \\begin{bmatrix}1 \\\\ 0 \\\\ 0\\end{bmatrix} = \\begin{bmatrix}0.1 \\\\ 0 \\\\ 0\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- Para $\\mathbf{x}_2$ (error = 1):\n",
    "\n",
    "$$\n",
    "\\mathbf{w}^1 = \\begin{bmatrix}0.1 \\\\ 0 \\\\ 0\\end{bmatrix} + 0.1 \\times 1 \\times \\begin{bmatrix}1 \\\\ 0 \\\\ 1\\end{bmatrix} = \\begin{bmatrix}0.2 \\\\ 0 \\\\ 0.1\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- Para $\\mathbf{x}_3$ (error = 1):\n",
    "\n",
    "$$\n",
    "\\mathbf{w}^1 = \\begin{bmatrix}0.2 \\\\ 0 \\\\ 0.1\\end{bmatrix} + 0.1 \\times 1 \\times \\begin{bmatrix}1 \\\\ 1 \\\\ 0\\end{bmatrix} = \\begin{bmatrix}0.3 \\\\ 0.1 \\\\ 0.1\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "## Resumen de la Iteración 2\n",
    "\n",
    "| Paso       | $\\mathbf{w}^1$ Inicial            | $\\hat{\\mathbf{y}}$      | $\\mathbf{y}$       | Error           | $\\mathbf{w}^2$ Final           | \n",
    "|------------|----------------------------------|-------------------------|--------------------|-----------------|-------------------------------|\n",
    "|            | $\\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}$ | $[0,\\ 0,\\ 0,\\ 0]$         | $[1,\\ 1,\\ 1,\\ 0]$  | $[1,\\ 1,\\ 1,\\ 0]$ | $\\begin{bmatrix} 0.3 \\\\ 0.1 \\\\ 0.1 \\end{bmatrix}$ |\n",
    "\n",
    "\r",
    "2\r\n",
    "\r\n",
    "$$\r\n",
    "ECM = \\frac{1}{4} (0^2 + 0^2 + 0^2 + (-1)^2) = \\frac{1}{4} = 0.25\r\n",
    "$$$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80389d06-18f8-420d-b4ef-17d957b6e0fb",
   "metadata": {},
   "source": [
    "## Iteración 3 (Epoch 3)\n",
    "\n",
    "\n",
    "### Paso 1: Pesos iniciales para esta iteración\n",
    "\n",
    "$$\n",
    "\\mathbf{w}^2 = \\begin{bmatrix} 0.3 \\\\ 0.1 \\\\ 0.1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### Paso 2: Cálculo de la salida lineal $z_i = \\mathbf{w}^2 \\cdot \\mathbf{x}_i$\n",
    "\n",
    "Para cada patrón $\\mathbf{x}_i$:\n",
    "\n",
    "- Para $\\mathbf{x}_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}$:\n",
    "\n",
    "$$\n",
    "z_1 = \\begin{bmatrix} 0.3 & 0.1 & 0.1 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix} = 0.3\n",
    "$$\n",
    "\n",
    "- Para $\\mathbf{x}_2 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\end{bmatrix}$:\n",
    "\n",
    "$$\n",
    "z_2 = \\begin{bmatrix} 0.3 & 0.1 & 0.1 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\end{bmatrix} = 0.3 + 0 + 0.1 = 0.4\n",
    "$$\n",
    "\n",
    "- Para $\\\\mathbf{x}_3 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix}$:\n",
    "\n",
    "$$\n",
    "z_3 = \\begin{bmatrix} 0.3 & 0.1 & 0.1 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix} = 0.3 + 0.1 + 0 = 0.4\n",
    "$$\n",
    "\n",
    "- Para $\\mathbf{x}_4 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix}$:\n",
    "\n",
    "$$\n",
    "z_4 = \\begin{bmatrix} 0.3 & 0.1 & 0.1 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix} = 0.3 + 0.1 + 0.1 = 0.5\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### Paso 3: Aplicar función escalón con umbral $\\theta = 0$\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\phi(z_i) = \\begin{cases}\n",
    "1 & \\text{si } z_i > 0 \\\\\n",
    "0 & \\text{si } z_i \\leq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Dado que todos los $z_i > 0$:\n",
    "\n",
    "$$\n",
    "\\hat{y}_1 = 1, \\quad \\hat{y}_2 = 1, \\quad \\hat{y}_3 = 1, \\quad \\hat{y}_4 = 1\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### Paso 4: Comparación de salida predicha vs esperada\n",
    "\n",
    "| Patrón $\\mathbf{x}_i$ | Salida esperada $y_i$ | Salida predicha $\\hat{y}_i$ | Error $e_i = y_i - \\hat{y}_i$ |\n",
    "|-----------------------|-----------------------|-----------------------------|-------------------------------|\n",
    "| $\\mathbf{x}_1$         | 1                     | 1                           | 0                             |\n",
    "| $\\mathbf{x}_2$         | 1                     | 1                           | 0                             |\n",
    "| $\\\\mathbf{x}_3$        | 1                     | 1                           | 0                             |\n",
    "| $\\mathbf{x}_4$         | 0                     | 1                           | -1                            |\n",
    "\n",
    "\n",
    "### Paso 5: Actualización de pesos\n",
    "\n",
    "Sólo hay error en $\\mathbf{x}_4$ con $e_4 = -1$:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}^3 = \\mathbf{w}^2 + \\eta \\, e_4 \\, \\mathbf{x}_4 = \\begin{bmatrix} 0.3 \\\\ 0.1 \\\\ 0.1 \\end{bmatrix} + 0.1 \\times (-1) \\times \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 0.2 \\\\ 0.0 \\\\ 0.0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "## Resumen de la Iteración 3\n",
    "\n",
    "| Paso       | $\\mathbf{w}^2$ Inicial           | $\\hat{\\mathbf{y}}$      | $\\mathbf{y}$       | Error           | $\\mathbf{w}^3$ Final           | \n",
    "|------------|---------------------------------|-------------------------|--------------------|-----------------|-------------------------------|\n",
    "|            | $\\begin{bmatrix} 0.3 \\\\ 0.1 \\\\ 0.1 \\end{bmatrix}$ | $[1,\\ 1,\\ 1,\\ 1]$         | $[1,\\ 1,\\ 1,\\ 0]$  | $[0,\\ 0,\\ 0,\\ -1]$ | $\\begin{bmatrix} 0.2 \\\\ 0.0 \\\\ 0.0 \\end{bmatrix}$ |\n",
    "\n",
    "\n",
    "\n",
    "### Error cuadrático medio (ECM) \n",
    "\n",
    "$$\n",
    "ECM = \\frac{1}{n} \\sum_{i=1}^{n} e_i^2 = \\frac{1}{4} (0^2 + 0^2 + 0^2 + (-1)^2) = \\frac{1}{4} (1) = 0.25\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bca0f-39f1-4fe6-850b-2e021b125d87",
   "metadata": {},
   "source": [
    "## Frontera de decisión del Perceptrón\n",
    "\n",
    "En el algoritmo del perceptrón, la frontera de decisión se define por la ecuación:\n",
    "\n",
    "$$\n",
    "z = w_0 + w_1 x_1 + w_2 x_2 = 0\n",
    "$$\n",
    "\n",
    "Si despejamos $x_2 $, obtenemos una línea recta en el plano $ (x_1, x_2) $:\n",
    "\n",
    "$$\n",
    "x_2 = -\\frac{w_1}{w_2} x_1 - \\frac{w_0}{w_2}\n",
    "$$\n",
    "\n",
    "Esta frontera separa las clases predichas por el perceptrón. A medida que el algoritmo entrena, esta frontera se va ajustando según los errores cometidos.\n",
    "\n",
    "A continuación se grafican los datos de entrada (con sus respectivas clases) y las fronteras de decisión para cada iteración.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c2faa-062d-46e1-b425-b04197fe8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Datos con bias (x0=1)\n",
    "X = np.array([\n",
    "    [1, 0, 0],  # x0 (bias), x1, x2\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0],\n",
    "    [1, 1, 1]\n",
    "])\n",
    "y = np.array([0, 0, 0, 1])  # Salidas esperadas\n",
    "\n",
    "# Parámetros\n",
    "eta = 0.1\n",
    "epochs = 30\n",
    "plot_epochs = [1, 2, 3, 4, 5]  # Solo iteraciones 1 y 2 para graficar\n",
    "w = np.array([0, 0, 0])  # Pesos iniciales\n",
    "weights_history = [w.copy()]\n",
    "errors = []\n",
    "mse_list = []  # Lista para guardar ECM por época\n",
    "\n",
    "# Entrenamiento (guardamos pesos y errores por época)\n",
    "for epoch in range(epochs):\n",
    "    total_error = 0\n",
    "    for i in range(len(X)):\n",
    "        z = np.dot(w, X[i])\n",
    "        y_hat = 1 if z > 0 else 0\n",
    "        e = y[i] - y_hat\n",
    "        if e != 0:\n",
    "            total_error += 1\n",
    "            w = w + eta * e * X[i]\n",
    "    weights_history.append(w.copy())\n",
    "    errors.append(total_error)\n",
    "\n",
    "    # Calcular predicciones para todo el dataset con los pesos actuales\n",
    "    y_pred = np.array([1 if np.dot(w, X[j]) > 0 else 0 for j in range(len(X))])\n",
    "    # Calcular ECM (MSE)\n",
    "    mse = np.mean((y - y_pred) ** 2)\n",
    "    mse_list.append(mse)\n",
    "\n",
    "# Mostrar ECM para iteraciones 1 y 2\n",
    "for ep in plot_epochs:\n",
    "    print(f\"Época {ep}: ECM = {mse_list[ep - 1]}\")\n",
    "\n",
    "# --- Gráfica del error por época ---\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(1, epochs + 1), errors, marker='o', color='red', label='Errores de clasificación')\n",
    "plt.plot(range(1, epochs + 1), mse_list, marker='x', color='blue', label='ECM')\n",
    "plt.title('Errores y ECM por Época durante el Entrenamiento')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Valor')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Graficar la evolución de la frontera de decisión en épocas seleccionadas ---\n",
    "filtered_weights = [weights_history[ep] for ep in plot_epochs]\n",
    "fig, axs = plt.subplots(1, len(plot_epochs), figsize=(6 * len(plot_epochs), 5))\n",
    "x_vals = np.array([-0.5, 1.5])\n",
    "\n",
    "for i, ep in enumerate(plot_epochs):\n",
    "    w_i = filtered_weights[i]\n",
    "    ax = axs[i] if len(plot_epochs) > 1 else axs\n",
    "\n",
    "    # Dibujar frontera de decisión si es posible\n",
    "    if w_i[2] != 0:\n",
    "        y_vals = - (w_i[1] / w_i[2]) * x_vals - (w_i[0] / w_i[2])\n",
    "        ax.plot(x_vals, y_vals, label=f'Frontera Epoch {ep}', color='blue')\n",
    "    elif w_i[1] != 0:\n",
    "        x_line = -w_i[0] / w_i[1]\n",
    "        ax.axvline(x_line, label=f'Frontera Epoch {ep}', color='blue')\n",
    "    else:\n",
    "        ax.text(0.1, 0.1, 'Frontera no definida', color='red')\n",
    "\n",
    "    # Dibujar puntos con diferentes marcadores según clase\n",
    "    for j in range(len(X)):\n",
    "        x1, x2 = X[j, 1], X[j, 2]\n",
    "        marker = 'o' if y[j] == 1 else 'x'\n",
    "        ax.scatter(x1, x2, marker=marker, c='black', s=100)\n",
    "\n",
    "    ax.set_title(f'Época {ep}')\n",
    "    ax.set_xlabel('$x_1$')\n",
    "    ax.set_ylabel('$x_2$')\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim(-0.5, 1.5)\n",
    "    ax.set_ylim(-0.5, 1.5)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a0cd28-1010-4d1a-aca0-ec464c74e764",
   "metadata": {},
   "source": [
    "## Propiedades del perceptrón\n",
    "\n",
    "- **Aprendizaje lineal**: solo puede aprender si los datos son **linealmente separables**\n",
    "- **Convergencia garantizada** (Teorema de convergencia del perceptrón) solo en ese caso\n",
    "- **Rápido y simple**, pero limitado en capacidad\n",
    "- Es el **bloque base** de redes neuronales más complejas\n",
    "\n",
    "\n",
    "\n",
    "## Limitaciones\n",
    "\n",
    "- No puede resolver problemas **no lineales**, como el clásico caso del **XOR** (exclusiva lógica)\n",
    "- Solo produce **salidas binarias**\n",
    "- No da probabilidades ni confianza en la predicción\n",
    "\n",
    "Por estas razones, se generalizó más tarde en modelos más poderosos, como el **Perceptrón Multicapa (MLP)**, que puede aprender representaciones no lineales gracias a la incorporación de **capas ocultas** y **funciones de activación no lineales** como la **sigmoide**, **tangente hiperbólica**, o **ReLU**.\n",
    "\n",
    "\n",
    "\n",
    "## Ejemplo de aplicación\n",
    "\n",
    "- Clasificar correos electrónicos como *spam* o *no spam*\n",
    "- Determinar si una imagen contiene un gato (sí/no)\n",
    "- Detección de fraudes simples\n",
    "- Clasificación de opiniones como *positiva* o *negativa*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca192355-4896-4dcd-8a73-614634c7de41",
   "metadata": {},
   "source": [
    "# Ejercicio: Entrenamiento de un Perceptrón Lineal con Pérdida Cuadrática\n",
    "\n",
    "Vamos a trabajar con un modelo simple de perceptrón lineal sin función de activación. Este modelo realiza una predicción lineal a partir de una entrada $\\mathbf{x} = (x_1, x_2)$, y ajusta sus pesos $w_1$ y $w_2$ para que la salida se aproxime a una etiqueta deseada $y$.\n",
    "\n",
    "La función de pérdida utilizada es la **pérdida cuadrática**:\n",
    "\n",
    "$$\n",
    "f(w_1, w_2) = \\frac{1}{2}(w_1 x_1 + w_2 x_2 - y)^2\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "## Datos Iniciales\n",
    "\n",
    "- Conjunto de entradas: \n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "2 & 3 \\\\\n",
    "3 & 5 \\\\\n",
    "5 & 2 \\\\\n",
    "6 & 1 \\\\\n",
    "7 & 3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- Etiquetas deseadas:\n",
    "\n",
    "$$\n",
    "y = \\begin{bmatrix} 0, 0, 0, 1, 1, 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- Pesos iniciales:\n",
    "  $$\n",
    "  w_1^{(0)} = 0, \\quad w_2^{(0)} = 0\n",
    "  $$\n",
    "\n",
    "- Tasa de aprendizaje: \n",
    "  $$\n",
    "  \\eta = 0.01\n",
    "  $$\n",
    "\n",
    "- Número de iteraciones: 100\n",
    "\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Implementar el entrenamiento del perceptrón con descenso por gradiente para minimizar la pérdida cuadrática y actualizar los pesos iterativamente, usando todos los datos del conjunto.\n",
    "\n",
    "\n",
    "\n",
    "## Pasos a Seguir en Cada Iteración\n",
    "\n",
    "Para cada iteración, realiza lo siguiente:\n",
    "\n",
    "1. Para cada dato $x_i = (x_{i1}, x_{i2})$ y etiqueta $y_i$:\n",
    "\n",
    "   - **Predicción del modelo:**\n",
    "\n",
    "   $$\n",
    "   \\hat{y}_i = w_1 \\cdot x_{i1} + w_2 \\cdot x_{i2}\n",
    "   $$\n",
    "\n",
    "   - **Cálculo del error:**\n",
    "\n",
    "   $$\n",
    "   e_i = \\hat{y}_i - y_i\n",
    "   $$\n",
    "\n",
    "   - **Cálculo de la pérdida para este dato:**\n",
    "\n",
    "   $$\n",
    "   f_i = \\frac{1}{2} e_i^2\n",
    "   $$\n",
    "\n",
    "   - **Cálculo del gradiente:**\n",
    "\n",
    "   $$\n",
    "   \\frac{\\partial f_i}{\\partial w_1} = e_i \\cdot x_{i1}, \\quad \\frac{\\partial f_i}{\\partial w_2} = e_i \\cdot x_{i2}\n",
    "   $$\n",
    "\n",
    "   - **Actualización de los pesos:**\n",
    "\n",
    "   $$\n",
    "   w_1 = w_1 - \\eta \\cdot \\frac{\\partial f_i}{\\partial w_1}\n",
    "   $$\n",
    "\n",
    "   $$\n",
    "   w_2 = w_2 - \\eta \\cdot \\frac{\\partial f_i}{\\partial w_2}\n",
    "   $$\n",
    "\n",
    "2. Al finalizar la iteración, calcula el error cuadrático medio (ECM):\n",
    "\n",
    "$$\n",
    "ECM = \\frac{1}{N} \\sum_{i=1}^N e_i^2\n",
    "$$\n",
    "\n",
    "y guarda su valor para analizar la evolución del entrenamiento.\n",
    "\n",
    "\n",
    "\n",
    "## Espacio para Respuestas (ejemplo para la primera iteración con el primer dato)\n",
    "\n",
    "- Predicción $\\hat{y}_1 = \\_\\_\\_\\_$\n",
    "- Error $e_1 = \\_\\_\\_\\_$\n",
    "- Pérdida $f_1 = \\_\\_\\_\\_$\n",
    "- Gradientes:\n",
    "  $$\n",
    "  \\frac{\\partial f_1}{\\partial w_1} = \\_\\_\\_\\_, \\quad \\frac{\\partial f_1}{\\partial w_2} = \\_\\_\\_\\_\n",
    "  $$\n",
    "- Pesos actualizados:\n",
    "  $$\n",
    "  w_1 = \\_\\_\\_\\_, \\quad w_2 = \\_\\_\\_\\_\n",
    "  $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- ¿Cómo cambia el ECM a lo largo de las iteraciones?\n",
    "- ¿Qué observas en la evolución de los pesos?\n",
    "- ¿Cómo afecta la tasa de aprendizaje $\\eta$ al proceso de entrenamiento?\n",
    "- ¿Crees que el perceptrón podrá separar correctamente las dos clases con esta función de pérdida?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75be86b-0190-4fcb-867f-34682c90e7de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
