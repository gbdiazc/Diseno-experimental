{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ace376a8-d411-49f2-a78e-be78619baf16",
   "metadata": {},
   "source": [
    "# Métodos Clásicos de Optimización para Problemas No Lineales sin Restricciones\n",
    "\n",
    "Dada una función escalar $f(\\mathbf{x}): \\mathbb{R}^n \\rightarrow \\mathbb{R}$, dos veces diferenciable y continua, se desea encontrar $\\mathbf{x} \\in \\mathbb{R}^n$ tal que:\n",
    "\n",
    "$$\n",
    "\\min_{\\mathbf{x} \\in \\mathbb{R}^n} f(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "## Mínimos\n",
    "\n",
    "- Un punto $\\mathbf{x}^* \\in \\mathbb{R}^n$ es un **mínimo global** de $f$ si:\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}^*) \\leq f(\\mathbf{x}) \\quad \\text{para todo } \\mathbf{x} \\in \\mathbb{R}^n\n",
    "$$\n",
    "\n",
    "- Un punto $\\mathbf{x}^*$ es un **mínimo local** de $f$ si existe un radio $r > 0$ tal que:\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}^*) \\leq f(\\mathbf{x}) \\quad \\text{para todo } \\mathbf{x} \\text{ tal que } \\|\\mathbf{x} - \\mathbf{x}^*\\| \\leq r\n",
    "$$\n",
    "\n",
    "- El mínimo global es un caso particular de mínimo local con la propiedad adicional de que ningún otro punto tiene un valor menor de $f$.\n",
    "\n",
    "\n",
    "\n",
    "## Condiciones de Optimalidad\n",
    "\n",
    "**Teorema:** Un punto $\\mathbf{x}^*$ es un mínimo local de $f$ si se cumplen las siguientes condiciones:\n",
    "\n",
    "1. **Condición de primer orden (punto estacionario):**\n",
    "\n",
    "$$\n",
    "\\nabla f(\\mathbf{x}^*) = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "2. **Condición de segundo orden:** La matriz Hessiana $\\nabla^2 f(\\mathbf{x}^*)$ es **definida positiva**:\n",
    "\n",
    "$$\n",
    "\\nabla^2 f(\\mathbf{x}^*) =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial^2 f}{\\partial x_1^2} & \\cdots & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_n} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial^2 f}{\\partial x_n \\partial x_1} & \\cdots & \\frac{\\partial^2 f}{\\partial x_n^2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "## Métodos Numéricos de Optimización\n",
    "\n",
    "Como resolver analíticamente este sistema puede ser complejo, se utilizan **métodos numéricos de descenso**, que se clasifican en:\n",
    "\n",
    "$$\n",
    "\\text{Métodos de Descenso} \\left\\{\n",
    "\\begin{matrix}\n",
    "\\text{Primer Orden} & \\left\\{ \\begin{matrix}\n",
    "\\text{Método del Gradiente} \\\\\n",
    "\\text{Gradiente Conjugado}\n",
    "\\end{matrix} \\right. \\\\\\\\\n",
    "\\text{Segundo Orden} & \\left\\{ \\begin{matrix}\n",
    "\\text{Método de Newton}\n",
    "\\end{matrix} \\right. \\\\\\\\\n",
    "\\text{Cuasi-Newton} & \\left\\{ \\begin{matrix}\n",
    "\\text{DFP (Davidon–Fletcher–Powell)} \\\\\n",
    "\\text{BFGS (Broyden–Fletcher–Goldfarb–Shanno)}\n",
    "\\end{matrix} \\right.\n",
    "\\end{matrix}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "## Propiedades de los Métodos\n",
    "\n",
    "### Método del Gradiente Descendente\n",
    "\n",
    "- Dirección de búsqueda: $-\\nabla f(\\mathbf{x}_k)$.\n",
    "- Paso $\\alpha_k$ debe cumplir: $\\nabla f(\\mathbf{x}_k + \\alpha_k \\mathbf{d}_k) \\cdot \\mathbf{d}_k = 0$ (difícil de cumplir exactamente, se usan aproximaciones).\n",
    "- **Convergencia lineal**: \n",
    "  $$\n",
    "  \\|\\mathbf{x}_{k+1} - \\mathbf{x}^*\\| \\leq \\lambda \\|\\mathbf{x}_k - \\mathbf{x}^*\\|, \\quad 0 < \\lambda < 1\n",
    "  $$\n",
    "- Direcciones consecutivas ortogonales.\n",
    "- Convergencia lenta, incluso para funciones cuadráticas.\n",
    "\n",
    "### Método del Gradiente Conjugado\n",
    "\n",
    "- Problema cuadrático: $f(\\mathbf{x}) = \\frac{1}{2} \\mathbf{x}^T Q \\mathbf{x} - \\mathbf{b}^T \\mathbf{x}$, con $Q$ definida positiva.\n",
    "- Las direcciones son $Q$-conjugadas.\n",
    "- **Convergencia exacta en a lo más $n$ pasos** (en aritmética exacta).\n",
    "\n",
    "### Método de Newton\n",
    "\n",
    "- Usa una aproximación cuadrática de $f$ para determinar el siguiente punto:\n",
    "  $$\n",
    "  \\mathbf{x}_{k+1} = \\mathbf{x}_k - t_k \\nabla^2 f(\\mathbf{x}_k)^{-1} \\nabla f(\\mathbf{x}_k)\n",
    "  $$\n",
    "- Requiere calcular y **almacenar la matriz Hessiana** y su inversa.\n",
    "- **Convergencia cuadrática** (muy rápida cerca del óptimo):\n",
    "  $$\n",
    "  \\|\\mathbf{x}_{k+1} - \\mathbf{x}^*\\| \\leq \\lambda \\|\\mathbf{x}_k - \\mathbf{x}^*\\|^2\n",
    "  $$\n",
    "- El punto inicial debe ser razonablemente cercano al óptimo.\n",
    "\n",
    ">  Evaluar derivadas de segundo orden (Hessiana) puede ser muy costoso: requiere $O(n^2)$ espacio y $O(n^3)$ operaciones para la inversión de matrices.\n",
    "\n",
    "### Métodos Cuasi-Newton\n",
    "\n",
    "- Sustituyen la Hessiana por una aproximación iterativa $S_k \\approx \\nabla^2 f(\\mathbf{x}_k)^{-1}$.\n",
    "- Fórmulas de actualización como DFP o BFGS permiten mantener buena convergencia sin cálculo explícito de derivadas de segundo orden.\n",
    "- Iteración típica:\n",
    "  $$\n",
    "  \\mathbf{x}_{k+1} = \\mathbf{x}_k - t_k S_k \\nabla f(\\mathbf{x}_k)\n",
    "  $$\n",
    "\n",
    "\n",
    "\n",
    "## Comparación de Métodos\n",
    "\n",
    "| Método               | Velocidad de Convergencia | Información Requerida           | Costo Computacional          |\n",
    "|----------------------|---------------------------|----------------------------------|-------------------------------|\n",
    "| Gradiente Descendente | Lineal                    | Gradiente                        | Bajo $\\mathcal{O}(n)$         |\n",
    "| Gradiente Conjugado   | Lineal (pero mejora)      | Gradiente, $Q$ definida positiva | Moderado $\\mathcal{O}(n^2)$   |\n",
    "| Newton                | Cuadrática (local)        | Gradiente + Hessiana             | Alto ($O(n^3)$ por iteración) |\n",
    "| Cuasi-Newton (BFGS)   | Superlineal               | Gradiente                        | Moderado $\\mathcal{O}(n^2)$   |\n",
    "\n",
    "\n",
    "### Notas:\n",
    "\n",
    "- El método de **Newton** requiere calcular y resolver un sistema con la Hessiana, lo cual es costoso pero ofrece convergencia cuadrática.\n",
    "- **BFGS** aproxima la Hessiana, evitando ese costo y logrando mejor rendimiento que el gradiente descendente.\n",
    "- **Gradiente Conjugado** es muy eficiente en problemas cuadráticos simétricos positivos definidos y converge en a lo sumo $n$ pasos exactos (en aritmética exacta)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13229e1-08fc-42e0-85cd-052076a3dd7b",
   "metadata": {},
   "source": [
    "# Ejemplo Comparativo de Métodos de Optimización en una Función Cuadrática\n",
    "\n",
    "En este ejemplo, consideramos el problema de minimizar la función cuadrática:\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}) = \\frac{1}{2} \\mathbf{x}^T Q \\mathbf{x} - \\mathbf{b}^T \\mathbf{x} =si,\n",
    "$$\n",
    "\n",
    "donde se definen:\n",
    "\n",
    " $$ Q = \\begin{bmatrix} 3 & 2 \\\\ 2 & 6 \\end{bmatrix}, $$\n",
    " $$ \\mathbf{b} = \\begin{bmatrix} 2 \\\\ -8 \\end{bmatrix}. $$\n",
    "\n",
    "La función es convexa y tiene un único mínimo global, el cual se obtiene al resolver\n",
    "\n",
    "$$\n",
    "Q \\mathbf{x} = \\mathbf{b}.\n",
    "$$\n",
    "\n",
    "Este ejemplo comparan los algoritmos de optimización sin restricciones:\n",
    "\r\n",
    "\r\n",
    "1. **Gradiente Descendente**:  \r\n",
    "   - Actualiza la solución en la dirección opuesta al gradiente:  \r\n",
    "     $$\r\n",
    "     \\mathbf{x}_{k+1} = \\mathbf{x}_k - \\alpha \\nabla f(\\mathbf{x}_k).\r\n",
    "     $$  \r\n",
    "   - Usa un tamaño de paso constante y requiere muchas iteraciones, lo que conduce a una convergencia lenta.\r\n",
    "\r\n",
    "2. **Gradiente Conjugado**:  \r\n",
    "   - Está diseñado para problemas cuadráticos como el anterior.  \r\n",
    "   - Genera direcciones de búsqueda que son $Q$-conjugadas, lo que permite llegar al mínimo en a lo sumo $n$ pasos (en aritmética exacta, para un problema de dimensión $n$).  \r\n",
    "   - En nuestro caso, al ser $n = 2$, converge en dos iteraciones.\r\n",
    "\r\n",
    "3. **Método de Newton**:  \r\n",
    "   - Aprovecha la información de la segunda derivada (la Hessiana) para ajustar la dirección del paso:  \r\n",
    "     $$\r\n",
    "     \\mathbf{x}_{k+1} = \\mathbf{x}_k - t_k \\nabla^2 f(\\mathbf{x}_k)^{-1} \\nabla f(\\mathbf{x}_k).\r\n",
    "     $$  \r\n",
    "   - Ofrece una convergencia cuadrática cerca del óptimo, reduciendo drásticamente el error en cada iteración.  \r\n",
    "   - Sin embargo, en problemas de mayor dimensión, el cálculo y la inversión de la Hessiana pueden resultar costosos.\r\n",
    "\r\n",
    "4. **Método Cuasi-Newton (BFGS)**:  \r\n",
    "   - Construye una aproximación iterativa a la inversa de la Hessiana, evitando calcularla directamente.  \r\n",
    "   - Actualiza la solución usando esta matriz aproximada:  \r\n",
    "     $$\r\n",
    "     \\mathbf{x}_{k+1} = \\mathbf{x}_k - \\alpha_k \\mathbf{S}_k \\nabla f(\\mathbf{x}_k),\r\n",
    "     $$  \r\n",
    "     donde $\\mathbf{S}_k$ es la aproximación a la inversa de la Hessiana en la iteración $k$.  \r\n",
    "   - La matriz $\\mathbf{S}_k$ se actualiza en cada paso usando diferencias de gradientes y soluciones previas, con la fórmula BFGS, garantizando que $\\mathbf{S}_k$ sea siempre positiva definida.  \r\n",
    "   - Combina la rapidez del método de Newton con un costo computacional mucho menor, siendo muy efectivo en problemas de gran dimensión.\r\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fd0d50-72ba-4e88-a9d2-51b56b930a81",
   "metadata": {},
   "source": [
    "Ejemplo:  minimizar la función cuadrática\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}) = \\frac{1}{2} \\mathbf{x}^T Q \\mathbf{x} - \\mathbf{b}^T \\mathbf{x}\n",
    "$$\n",
    "\n",
    "donde \n",
    "\n",
    "$$\n",
    "Q = \\begin{bmatrix} 3 & 2 \\\\ 2 & 6 \\end{bmatrix}, \\quad \\mathbf{b} = \\begin{bmatrix} 2 \\\\ -8 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Esta función es estrictamente convexa porque la matriz $Q$ es simétrica definida positiva, por lo que tiene un único mínimo global.\n",
    "Se\n",
    "1. **Gradiente Descendente**:  \n",
    "- Actualiza la solución en la dirección opuesta al gradiente de la función en el punto actual:  \n",
    "  $$\n",
    "  \\mathbf{x}_{k+1} = \\mathbf{x}_k - \\alpha_k \\nabla f(\\mathbf{x}_k),\n",
    "  $$  \n",
    "  donde $\\alpha_k > 0$ es el tamaño de paso o tasa de aprendizaje en la iteración $k$.  \n",
    "- El gradiente $\\nabla f(\\mathbf{x}_k)$ indica la dirección de máximo aumento de la función, por lo que movernos en la dirección opuesta reduce el valor de $f$.  \n",
    "- El tamaño de paso $\\alpha_k$ puede ser constante o calculado adaptativamente (por ejemplo, usando búsqueda en línea).  \n",
    "- Este método es sencillo pero puede requerir muchas iteraciones para converger, especialmente si la función tiene curvas muy pronunciadas o es mal condicionada.  \n",
    "- La convergencia es generalmente lineal y depende mucho de la elección de $\\alpha_k$.\n",
    "\n",
    "2. **Gradiente Conjugado**:  \n",
    "   - Está diseñado para problemas cuadráticos como el anterior.  \n",
    "   - Genera direcciones de búsqueda que son $Q$-conjugadas, lo que permite llegar al mínimo en a lo sumo $n$ pasos (en aritmética exacta, para un problema de dimensión $n$).  \n",
    "   - En cada iteración, la solución se actualiza en la dirección conjugada:  \n",
    "     $$\n",
    "     \\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{p}_k,\n",
    "     $$  \n",
    "     donde $\\mathbf{p}_k$ es la dirección conjugada en la iteración $k$, y el tamaño de paso $\\alpha_k$ se calcula como  \n",
    "     $$\n",
    "     \\alpha_k = \\frac{\\mathbf{r}_k^T \\mathbf{r}_k}{\\mathbf{p}_k^T Q \\mathbf{p}_k},\n",
    "     $$  \n",
    "     siendo $\\mathbf{r}_k = \\nabla f(\\mathbf{x}_k)$ el residuo o gradiente en la iteración $k$.  \n",
    "   - La nueva dirección conjugada se actualiza con  \n",
    "     $$\n",
    "     \\mathbf{p}_{k+1} = -\\mathbf{r}_{k+1} + \\beta_k \\mathbf{p}_k,\n",
    "     $$  \n",
    "     donde  \n",
    "     $$\n",
    "     \\beta_k = \\frac{\\mathbf{r}_{k+1}^T \\mathbf{r}_{k+1}}{\\mathbf{r}_k^T \\mathbf{r}_k}.\n",
    "     $$  \n",
    "   - En nuestro caso, al ser $n = 2$, converge en dos iteraciones.\n",
    "\n",
    "3. **Método de Newton**:  \n",
    "   - Aprovecha la información de la segunda derivada (la Hessiana) para ajustar la dirección del paso:  \n",
    "     $$\n",
    "     \\mathbf{x}_{k+1} = \\mathbf{x}_k - t_k \\nabla^2 f(\\mathbf{x}_k)^{-1} \\nabla f(\\mathbf{x}_k).\n",
    "     $$  \n",
    "   - Ofrece una convergencia cuadrática cerca del óptimo, reduciendo drásticamente el error en cada iteración.  \n",
    "   - Sin embargo, en problemas de mayor dimensión, el cálculo y la inversión de la Hessiana pueden resultar costosos.\n",
    "\n",
    "4. **Método Cuasi-Newton (BFGS)**:  \n",
    "   - Construye una aproximación iterativa a la inversa de la Hessiana, evitando calcularla directamente.  \n",
    "   - Actualiza la solución usando esta matriz aproximada:  \n",
    "     $$\n",
    "     \\mathbf{x}_{k+1} = \\mathbf{x}_k - \\alpha_k \\mathbf{S}_k \\nabla f(\\mathbf{x}_k),\n",
    "     $$  \n",
    "     donde $\\mathbf{S}_k$ es la aproximación a la inversa de la Hessiana en la iteración $k$.  \n",
    "   - La matriz $\\mathbf{S}_k$ se actualiza en cada paso usando diferencias de gradientes y soluciones previas, con la fórmula BFGS, garantizando que $\\mathbf{S}_k$ sea siempre positiva definida.  \n",
    "   - Combina la rapidez del método de Newton con un costo computacional mucho menor, siendo muy efectivo en problemas de gran dimensión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a6e1d1-1935-4706-b536-92522dafb50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Función cuadrática: f(x) = (1/2) x^T Q x - b^T x\n",
    "Q = np.array([[3.0, 2.0], [2.0, 6.0]])\n",
    "b = np.array([2.0, -8.0])\n",
    "\n",
    "def f(x):\n",
    "    return 0.5 * x.T @ Q @ x - b.T @ x\n",
    "\n",
    "def grad_f(x):\n",
    "    return Q @ x - b\n",
    "\n",
    "def hess_f(x):\n",
    "    return Q\n",
    "\n",
    "# Parámetros\n",
    "x0 = np.array([0.0, 0.0])\n",
    "tol = 1e-6\n",
    "max_iter = 50\n",
    "\n",
    "# Gradiente Descendente con paso fijo\n",
    "def gradient_descent(x0, alpha=0.1):\n",
    "    xk = x0.copy()\n",
    "    history = [xk.copy()]\n",
    "    for _ in range(max_iter):\n",
    "        grad = grad_f(xk)\n",
    "        if np.linalg.norm(grad) < tol:\n",
    "            break\n",
    "        xk = xk - alpha * grad\n",
    "        history.append(xk.copy())\n",
    "    return np.array(history)\n",
    "\n",
    "# Newton con paso completo\n",
    "def newton_method(x0):\n",
    "    xk = x0.copy()\n",
    "    history = [xk.copy()]\n",
    "    for _ in range(max_iter):\n",
    "        grad = grad_f(xk)\n",
    "        if np.linalg.norm(grad) < tol:\n",
    "            break\n",
    "        H = hess_f(xk)\n",
    "        delta = np.linalg.solve(H, grad)\n",
    "        xk = xk - delta\n",
    "        history.append(xk.copy())\n",
    "    return np.array(history)\n",
    "\n",
    "# Cuasi-Newton BFGS con paso completo (alpha=1)\n",
    "def bfgs_method(x0):\n",
    "    xk = x0.copy()\n",
    "    n = len(x0)\n",
    "    Hk = np.eye(n)\n",
    "    history = [xk.copy()]\n",
    "    for _ in range(max_iter):\n",
    "        grad = grad_f(xk)\n",
    "        if np.linalg.norm(grad) < tol:\n",
    "            break\n",
    "        pk = -Hk @ grad\n",
    "        xk_new = xk + pk  # paso completo (alpha=1)\n",
    "        sk = xk_new - xk\n",
    "        yk = grad_f(xk_new) - grad\n",
    "        if yk.T @ sk > 1e-10:\n",
    "            rho = 1.0 / (yk.T @ sk)\n",
    "            I = np.eye(n)\n",
    "            Hk = (I - rho * np.outer(sk, yk)) @ Hk @ (I - rho * np.outer(yk, sk)) + rho * np.outer(sk, sk)\n",
    "        xk = xk_new\n",
    "        history.append(xk.copy())\n",
    "    return np.array(history)\n",
    "\n",
    "# Gradiente Conjugado\n",
    "def conjugate_gradient(x0):\n",
    "    xk = x0.copy()\n",
    "    r = grad_f(xk)\n",
    "    p = -r\n",
    "    history = [xk.copy()]\n",
    "    for _ in range(max_iter):\n",
    "        Ap = Q @ p\n",
    "        alpha = r.T @ r / (p.T @ Ap)\n",
    "        xk = xk + alpha * p\n",
    "        r_new = r + alpha * Ap\n",
    "        history.append(xk.copy())\n",
    "        if np.linalg.norm(r_new) < tol:\n",
    "            break\n",
    "        beta = r_new.T @ r_new / (r.T @ r)\n",
    "        p = -r_new + beta * p\n",
    "        r = r_new\n",
    "    return np.array(history)\n",
    "\n",
    "# Ejecutar métodos\n",
    "gd_hist = gradient_descent(x0)\n",
    "nt_hist = newton_method(x0)\n",
    "bfgs_hist = bfgs_method(x0)\n",
    "cg_hist = conjugate_gradient(x0)\n",
    "\n",
    "# Punto óptimo analítico\n",
    "optimum = np.linalg.solve(Q, b)\n",
    "\n",
    "# Distancia al óptimo para cada iteración\n",
    "def distance(history):\n",
    "    return np.linalg.norm(history - optimum, axis=1)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.semilogy(distance(gd_hist), label='Gradiente Descendente')\n",
    "plt.semilogy(distance(nt_hist), label='Newton')\n",
    "plt.semilogy(distance(bfgs_hist), label='BFGS (Cuasi-Newton)')\n",
    "plt.semilogy(distance(cg_hist), label='Gradiente Conjugado')\n",
    "plt.xlabel('Iteraciones')\n",
    "plt.ylabel('Distancia al mínimo (escala logarítmica)')\n",
    "plt.title('Convergencia de Métodos de Optimización')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770eeea8-0c6c-4993-ac7e-a2aca3a1ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Función para calcular el valor de f en la última solución de cada método\n",
    "def f_val(ultimo_punto):\n",
    "    return f(ultimo_punto)\n",
    "\n",
    "# Crear datos para la tabla\n",
    "data = {\n",
    "    \"Método\": [\"Gradiente Descendente\", \"Newton\", \"BFGS (Cuasi-Newton)\", \"Gradiente Conjugado\"],\n",
    "    \"Iteraciones\": [len(gd_hist)-1, len(nt_hist)-1, len(bfgs_hist)-1, len(cg_hist)-1],\n",
    "    \"Solución encontrada\": [gd_hist[-1], nt_hist[-1], bfgs_hist[-1], cg_hist[-1]],\n",
    "    \"Valor mínimo alcanzado\": [f_val(gd_hist[-1]), f_val(nt_hist[-1]), f_val(bfgs_hist[-1]), f_val(cg_hist[-1])]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Formatear columnas para que se vean mejor\n",
    "df[\"Solución encontrada\"] = df[\"Solución encontrada\"].apply(lambda x: np.round(x, 6))\n",
    "df[\"Valor mínimo alcanzado\"] = df[\"Valor mínimo alcanzado\"].apply(lambda x: round(x, 6))\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b7a5b-0303-40bc-9063-558fa0dd4d61",
   "metadata": {},
   "source": [
    "## Método de Gradiente Descendente \n",
    "\n",
    "Dada una función diferenciable \n",
    "$$\n",
    "f : \\mathbb{R}^n \\to \\mathbb{R}\n",
    "$$\n",
    "que queremos minimizar, el método de **gradiente descendente** genera una secuencia de puntos \n",
    "$$\n",
    "\\{\\mathbf{x}_k\\}\n",
    "$$\n",
    "a partir de una solución inicial $\\mathbf{x}_0$, actualizando iterativamente mediante la regla\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{k+1} = \\mathbf{x}_k - t_k \\nabla f(\\mathbf{x}_k), \\quad k=0,1,2,\\ldots\n",
    "$$\n",
    "\n",
    "donde $\\nabla f(\\mathbf{x}_k)$ es el gradiente de la función en $\\mathbf{x}_k$, y $t_k > 0$ es el tamaño de paso o *learning rate*.\n",
    "\n",
    "\n",
    "### Intuición del método\n",
    "\n",
    "- El gradiente $\\nabla f(\\mathbf{x}_k)$ apunta en la dirección de máximo crecimiento de la función $f$, por lo que su negativo, $-\\nabla f(\\mathbf{x}_k)$, es la dirección de máximo descenso local.  \n",
    "- Actualizando $\\mathbf{x}_k$ en esa dirección se busca reducir el valor de la función en cada paso, acercándose al mínimo.\n",
    "\n",
    "\n",
    "### Selección del tamaño de paso $t_k$\n",
    "\n",
    "- En la práctica, $t_k$ puede ser:\n",
    "  - Un valor fijo pequeño (constante en todas las iteraciones).\n",
    "  - Un valor que disminuye con $k$ (para garantizar convergencia).\n",
    "  - Determinado mediante métodos heurísticos o reglas de búsqueda (por ejemplo, búsqueda en línea o backtracking).\n",
    "  \n",
    "- La elección adecuada de $t_k$ es crucial:\n",
    "  - Si $t_k$ es muy pequeño, la convergencia es muy lenta.\n",
    "  - Si $t_k$ es muy grande, puede que no se reduzca el valor de $f$ o que el método diverja.\n",
    "\n",
    "\n",
    "### Resumen del algoritmo\n",
    "\n",
    "1. Inicializar $\\mathbf{x}_0$.\n",
    "2. Para $k = 0, 1, 2, \\ldots$ hasta convergencia:\n",
    "   - Calcular el gradiente $\\nabla f(\\mathbf{x}_k)$.\n",
    "   - Elegir un tamaño de paso $t_k$.\n",
    "   - Actualizar la solución:\n",
    "     $$\n",
    "     \\mathbf{x}_{k+1} = \\mathbf{x}_k - t_k \\nabla f(\\mathbf{x}_k).\n",
    "     $$\n",
    "3. Detener cuando el gradiente es suficientemente pequeño o se alcanza un máximo de iteraciones.\n",
    "\n",
    "\n",
    "Este método es simple y ampliamente utilizado, especialmente en problemas de optimización con muchas variables, aunque puede ser lento si no se elige adecuadamente el tamaño de paso o si la función tiene regiones planas o curvas pronunciadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0e7a92-cf6d-4e0a-9f1f-1a80cd874703",
   "metadata": {},
   "source": [
    "Consideremos la función\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}) = x_1^2 + 2x_2^2,\n",
    "$$\n",
    "\n",
    "donde \\(\\mathbf{x} = (x_1, x_2) \\in \\mathbb{R}^2\\).\n",
    "\n",
    "### Cálculo del mínimo analíticamente usando derivadas\n",
    "\n",
    "1. Calculamos el gradiente de \\(f\\):\n",
    "\n",
    "$$\n",
    "\\nabla f(\\mathbf{x}) = \\left[\\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}\\right] = [2x_1, 4x_2].\n",
    "$$\n",
    "\n",
    "2. Para encontrar los puntos críticos, igualamos el gradiente a cero:\n",
    "\n",
    "$$\n",
    "\\nabla f(\\mathbf{x}) = \\mathbf{0} \\implies \n",
    "\\begin{cases}\n",
    "2x_1 = 0 \\\\\n",
    "4x_2 = 0\n",
    "\\end{cases} \\implies (x_1, x_2) = (0, 0).\n",
    "$$\n",
    "\n",
    "3. Calculamos la matriz Hessiana de \\(f\\):\n",
    "\n",
    "$$\n",
    "H = \\begin{bmatrix}\n",
    "\\frac{\\partial^2 f}{\\partial x_1^2} & \\frac{\\partial^2 f}{\\partial x_1 \\partial x_2} \\\\\n",
    "\\frac{\\partial^2 f}{\\partial x_2 \\partial x_1} & \\frac{\\partial^2 f}{\\partial x_2^2}\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "2 & 0 \\\\\n",
    "0 & 4\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "4. Calculamos los valores propios de la Hessiana \\(H\\) para verificar su positividad:\n",
    "\n",
    "$$\n",
    "\\det(H - \\lambda I) = \\det \\begin{bmatrix}\n",
    "2 - \\lambda & 0 \\\\\n",
    "0 & 4 - \\lambda\n",
    "\\end{bmatrix} = (2 - \\lambda)(4 - \\lambda) = 0.\n",
    "$$\n",
    "\n",
    "De donde obtenemos los valores propios:\n",
    "\n",
    "$$\n",
    "\\lambda_1 = 2, \\quad \\lambda_2 = 4.\n",
    "$$\n",
    "\n",
    "Dado que ambos valores propios son positivos, la matriz Hessiana es positiva definida.\n",
    "\n",
    "\n",
    "\n",
    "La función $f(\\mathbf{x})$ es convexa y tiene un único mínimo global en $\\mathbf{x} = (0,0)$, donde\n",
    "\n",
    "$$\n",
    "f(0,0) = 0.\n",
    "$$\n",
    "\n",
    "El método de gradiente descendente iterativamente aproxima este mínimo actualizando la solución en la dirección opuesta al gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1fcce-f38e-41fd-95a2-ce9efffa937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f(x):\n",
    "    # Función objetivo\n",
    "    return x[0]**2 + 2*x[1]**2\n",
    "\n",
    "def grad_f(x):\n",
    "    # Gradiente de la función\n",
    "    return np.array([2*x[0], 4*x[1]])\n",
    "\n",
    "def gradiente_descendente(x0, t, tol=1e-6, max_iter=1000):\n",
    "    xk = x0.copy()\n",
    "    history = [f(xk)]\n",
    "    \n",
    "    for k in range(max_iter):\n",
    "        g = grad_f(xk)\n",
    "        if np.linalg.norm(g) < tol:\n",
    "            break\n",
    "        xk = xk - t * g\n",
    "        history.append(f(xk))\n",
    "    return history\n",
    "\n",
    "# Punto inicial\n",
    "x0 = np.array([2.0, 2.0])\n",
    "\n",
    "# Valores de learning rate a probar\n",
    "learning_rates = [0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for t in learning_rates:\n",
    "    valores = gradiente_descendente(x0, t)\n",
    "    plt.plot(valores, label=f\"t = {t}\")\n",
    "\n",
    "plt.yscale(\"log\")  # Escala logarítmica para ver mejor la convergencia\n",
    "plt.xlabel(\"Iteración\")\n",
    "plt.ylabel(\"Valor de $f(x_k)$\")\n",
    "plt.title(\"Convergencia del gradiente descendente para distintos tamaños de paso\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730bad17-9ecd-4ddb-b1e9-ede5fc79f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def f(x):\n",
    "    return x[0]**2 + 2*x[1]**2\n",
    "\n",
    "def grad_f(x):\n",
    "    return np.array([2*x[0], 4*x[1]])\n",
    "\n",
    "def gradiente_descendente(x0, t, tol=1e-6, max_iter=1000):\n",
    "    xk = x0.copy()\n",
    "    history = [xk.copy()]\n",
    "    for k in range(max_iter):\n",
    "        g = grad_f(xk)\n",
    "        if np.linalg.norm(g) < tol:\n",
    "            break\n",
    "        xk = xk - t * g\n",
    "        history.append(xk.copy())\n",
    "    return np.array(history)\n",
    "\n",
    "x_vals = np.linspace(-3, 3, 100)\n",
    "y_vals = np.linspace(-3, 3, 100)\n",
    "X, Y = np.meshgrid(x_vals, y_vals)\n",
    "Z = X**2 + 2*Y**2\n",
    "\n",
    "x0 = np.array([2.0, 2.0])\n",
    "learning_rates = [0.01, 0.1, 0.2, 0.4, 0.5]\n",
    "\n",
    "fig = plt.figure(figsize=(12,9))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.plot_surface(X, Y, Z, alpha=0.5, cmap='viridis', edgecolor='none')\n",
    "\n",
    "for t in learning_rates:\n",
    "    tray = gradiente_descendente(x0, t)\n",
    "    z_tray = np.array([f(p) for p in tray])\n",
    "    ax.plot(tray[:,0], tray[:,1], z_tray, label=f't = {t}', marker='o')\n",
    "\n",
    "ax.set_xlabel('$x_1$')\n",
    "ax.set_ylabel('$x_2$')\n",
    "ax.set_zlabel('$f(x_1, x_2)$')\n",
    "ax.set_title('Trayectorias del gradiente descendente sobre $f(x_1, x_2) = x_1^2 + 2x_2^2$')\n",
    "\n",
    "# Cambiar ángulo de vista para mejor visualización\n",
    "ax.view_init(elev=45, azim=210)\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90765c7-4415-4647-a20a-6e1976c63756",
   "metadata": {},
   "source": [
    "# Gradiente Descendente con paso exacto\n",
    "\n",
    "Consideremos una función diferenciable $f : \\mathbb{R}^n \\to \\mathbb{R}$. Dado un punto inicial $\\mathbf{x}_0$, el gradiente\n",
    "\n",
    "$$\n",
    "\\nabla f(\\mathbf{x}) = \\left[\\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\ldots, \\frac{\\partial f}{\\partial x_n} \\right]^T\n",
    "$$\n",
    "\n",
    "indica la dirección de máximo aumento, por lo que la dirección de descenso es\n",
    "\n",
    "$$\n",
    "-\\nabla f(\\mathbf{x}_0).\n",
    "$$\n",
    "\n",
    "\n",
    "## Definición de la Función Unidimensional $\\phi_k(t)$\n",
    "\n",
    "Para encontrar el tamaño de paso $t_k$ que minimiza $f$ en la dirección de descenso, definimos:\n",
    "\n",
    "$$\n",
    "\\phi_k(t) = f\\left( \\mathbf{x}_k - t \\nabla f(\\mathbf{x}_k) \\right).\n",
    "$$\n",
    "\n",
    "Esta es una función de una variable $t \\geq 0$, que indica el valor de $f$ al movernos desde $\\mathbf{x}_k$ en la dirección de máximo descenso.\n",
    "\n",
    "\n",
    "\n",
    "## Cálculo de $t_k$ que Minimiza $\\phi_k(t)$\n",
    "\n",
    "El objetivo es encontrar\n",
    "\n",
    "$$\n",
    "t_k = \\arg\\min_{t > 0} \\phi_k(t).\n",
    "$$\n",
    "\n",
    "Para esto podemos:\n",
    "\n",
    "1. Derivar $\\phi_k(t)$ respecto a $t$:\n",
    "\n",
    "$$\n",
    "\\phi_k'(t) = \\frac{d}{dt} f\\left( \\mathbf{x}_k - t \\nabla f(\\mathbf{x}_k) \\right).\n",
    "$$\n",
    "\n",
    "2. Igualar a cero para encontrar puntos críticos:\n",
    "\n",
    "$$\n",
    "\\phi_k'(t) = 0.\n",
    "$$\n",
    "\n",
    "3. Confirmar que el punto encontrado corresponde a un mínimo (por ejemplo, $\\phi_k''(t) > 0$).\n",
    "\n",
    "\n",
    "\n",
    "## Ejemplo Sencillo\n",
    "\n",
    "Tomemos la función unidimensional\n",
    "\n",
    "$$\n",
    "f(x) = (x - 3)^2,\n",
    "$$\n",
    "\n",
    "que tiene su mínimo global en $x = 3$.\n",
    "\n",
    "### Paso 1: Calculamos el gradiente (derivada)\n",
    "\n",
    "$$\n",
    "\\nabla f(x) = 2(x - 3).\n",
    "$$\n",
    "\n",
    "Supongamos que partimos desde $x_0 = 0$.\n",
    "\n",
    "### Paso 2: Definimos la función $\\phi_0(t)$\n",
    "\n",
    "$$\n",
    "\\phi_0(t) = f\\big(x_0 - t \\nabla f(x_0)\\big) = f\\big(0 - t \\cdot 2(0 - 3)\\big) = f(0 + 6t) = (6t - 3)^2.\n",
    "$$\n",
    "\n",
    "### Paso 3: Derivamos $\\phi_0(t)$\n",
    "\n",
    "$$\n",
    "\\phi_0'(t) = 2(6t - 3) \\cdot 6 = 12(6t - 3).\n",
    "$$\n",
    "\n",
    "### Paso 4: Igualamos a cero y resolvemos para $t$\n",
    "\n",
    "$$\n",
    "\\phi_0'(t) = 0 \\quad \\Rightarrow \\quad 12(6t - 3) = 0 \\quad \\Rightarrow \\quad 6t - 3 = 0 \\quad \\Rightarrow \\quad t = \\frac{1}{2}.\n",
    "$$\n",
    "\n",
    "### Paso 5: Actualizamos la solución\n",
    "\n",
    "$$\n",
    "x_1 = x_0 - t \\nabla f(x_0) = 0 - \\frac{1}{2} \\cdot 2 (0 - 3) = 0 - \\frac{1}{2} \\cdot (-6) = 3.\n",
    "$$\n",
    "\n",
    "En una sola iteración hemos llegado al mínimo exacto $x=3$.\n",
    "\n",
    "\n",
    "\n",
    "## Resumen del Método\n",
    "\n",
    "1. En cada iteración $k$, calculamos el gradiente $\\nabla f(\\mathbf{x}_k)$.\n",
    "2. Definimos la función unidimensional\n",
    "\n",
    "$$\n",
    "\\phi_k(t) = f\\left(\\mathbf{x}_k - t \\nabla f(\\mathbf{x}_k)\\right).\n",
    "$$\n",
    "\n",
    "3. Calculamos $t_k$ minimizando $\\phi_k(t)$ (derivando e igualando a cero).\n",
    "4. Actualizamos\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{k+1} = \\mathbf{x}_k - t_k \\nabla f(\\mathbf{x}_k).\n",
    "$$\n",
    "\n",
    "5. Repetimos hasta convergencia.\n",
    "\n",
    "\n",
    "Esta forma de calcular el paso exacto garantiza que en cada iteración se avanza optimizando el tamaño del paso para acelerar la convergencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7c191a-dd5b-4983-9548-33317f6617bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Función objetivo unidimensional\n",
    "def f(x):\n",
    "    return (x - 3)**2\n",
    "\n",
    "# Derivada de la función (gradiente)\n",
    "def grad_f(x):\n",
    "    return 2 * (x - 3)\n",
    "\n",
    "# Definimos phi_k(t) = f(x_k - t * grad_f(x_k))\n",
    "def phi(t, xk):\n",
    "    return f(xk - t * grad_f(xk))\n",
    "\n",
    "# Derivada de phi_k(t) respecto a t (calculada analíticamente)\n",
    "def dphi_dt(t, xk):\n",
    "    # grad_f(xk) es 2(xk - 3)\n",
    "    # phi(t) = (xk - t*grad_f(xk) - 3)^2\n",
    "    # phi'(t) = 2 * (xk - t*grad_f(xk) - 3) * (-grad_f(xk))\n",
    "    return 2 * (xk - t * grad_f(xk) - 3) * (-grad_f(xk))\n",
    "\n",
    "# Búsqueda exacta de t_k (resolviendo dphi_dt(t) = 0)\n",
    "def exact_line_search(xk):\n",
    "    # Igualamos dphi_dt(t) = 0:\n",
    "    # 2 * (xk - t*grad_f(xk) - 3) * (-grad_f(xk)) = 0\n",
    "    # Se anula si (xk - t*grad_f(xk) - 3) = 0\n",
    "    gk = grad_f(xk)\n",
    "    return (xk - 3) / gk  # cuidado con la división por cero\n",
    "\n",
    "# Gradiente descendente con búsqueda exacta\n",
    "def gradient_descent_exact(x0, tol=1e-6, max_iter=100):\n",
    "    xk = x0\n",
    "    history = [xk]\n",
    "    for i in range(max_iter):\n",
    "        gk = grad_f(xk)\n",
    "        if abs(gk) < tol:\n",
    "            print(f\"Convergencia alcanzada en iteración {i}\")\n",
    "            break\n",
    "        tk = exact_line_search(xk)\n",
    "        xk = xk - tk * gk\n",
    "        history.append(xk)\n",
    "    return xk, history\n",
    "\n",
    "# Ejecutar gradiente descendente desde x0=0\n",
    "x0 = 0.0\n",
    "xmin, history = gradient_descent_exact(x0)\n",
    "\n",
    "print(f\"Mínimo encontrado en x = {xmin}\")\n",
    "\n",
    "# Graficar la función y el proceso de minimización\n",
    "x_vals = np.linspace(-1, 5, 400)\n",
    "f_vals = f(x_vals)\n",
    "\n",
    "plt.plot(x_vals, f_vals, label=\"f(x) = (x-3)^2\")\n",
    "plt.plot(history, [f(x) for x in history], 'ro-', label=\"Iteraciones GD\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.title(\"Gradiente Descendente con Búsqueda Exacta del Paso\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685b2a9f-1ca5-46b2-8078-fed756417c74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
