{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b596bf10-fbe7-4f37-b6b9-2690204e573d",
   "metadata": {},
   "source": [
    "# Solucion una epoca completa sobre los 6 datos\n",
    "\n",
    "Datos iniciales:  \n",
    "- Pesos iniciales:  \n",
    "  $w_1^{(0)} = 0$, $w_2^{(0)} = 0$  \n",
    "- Tasa de aprendizaje:  \n",
    "  $\\eta = 0.01$  \n",
    "\n",
    "Datos y etiquetas:  \n",
    "| Índice | $x_1$ | $x_2$ | Etiqueta $y$ |\n",
    "|--------|-------|-------|--------------|\n",
    "| 1      | 1     | 2     | 0            |\n",
    "| 2      | 2     | 3     | 0            |\n",
    "| 3      | 3     | 5     | 0            |\n",
    "| 4      | 5     | 2     | 1            |\n",
    "| 5      | 6     | 1     | 1            |\n",
    "| 6      | 7     | 3     | 1            |\n",
    "\n",
    "\n",
    "\n",
    "## Iteración 1 (dato 1: $\\mathbf{x}=(1,2)$, $y=0$)\n",
    "\n",
    "- Predicción:  \n",
    "  $$\\hat{y} = 0 \\cdot 1 + 0 \\cdot 2 = 0$$  \n",
    "- Error:  \n",
    "  $$e = \\hat{y} - y = 0 - 0 = 0$$  \n",
    "- Pérdida:  \n",
    "  $$f = \\frac{1}{2} \\cdot 0^2 = 0$$  \n",
    "- Gradientes:  \n",
    "  $$\\frac{\\partial f}{\\partial w_1} = 0 \\cdot 1 = 0, \\quad \\frac{\\partial f}{\\partial w_2} = 0 \\cdot 2 = 0$$  \n",
    "- Pesos actualizados:  \n",
    "  $$w_1 = 0 - 0.01 \\times 0 = 0, \\quad w_2 = 0 - 0.01 \\times 0 = 0$$\n",
    "\n",
    "\n",
    "\n",
    "## Iteración 2 (dato 2: $\\mathbf{x}=(2,3)$, $y=0$)\n",
    "\n",
    "- Predicción:  \n",
    "  $$\\hat{y} = 0 \\cdot 2 + 0 \\cdot 3 = 0$$  \n",
    "- Error:  \n",
    "  $$e = 0 - 0 = 0$$  \n",
    "- Pérdida:  \n",
    "  $$f = 0$$  \n",
    "- Gradientes:  \n",
    "  $$0, 0$$  \n",
    "- Pesos:  \n",
    "  $$w_1 = 0, \\quad w_2 = 0$$\n",
    "\n",
    "\n",
    "\n",
    "## Iteración 3 (dato 3: $\\mathbf{x}=(3,5)$, $y=0$)\n",
    "\n",
    "- Predicción:  \n",
    "  $$\\hat{y} = 0 \\cdot 3 + 0 \\cdot 5 = 0$$  \n",
    "- Error:  \n",
    "  $$0$$  \n",
    "- Pérdida:  \n",
    "  $$0$$  \n",
    "- Gradientes:  \n",
    "  $$0, 0$$  \n",
    "- Pesos:  \n",
    "  $$w_1 = 0, \\quad w_2 = 0$$\n",
    "\n",
    "\n",
    "\n",
    "## Iteración 4 (dato 4: $\\mathbf{x}=(5,2)$, $y=1$)\n",
    "\n",
    "- Predicción:  \n",
    "  $$\\hat{y} = 0 \\cdot 5 + 0 \\cdot 2 = 0$$  \n",
    "- Error:  \n",
    "  $$e = 0 - 1 = -1$$  \n",
    "- Pérdida:  \n",
    "  $$f = \\frac{1}{2} \\times (-1)^2 = 0.5$$  \n",
    "- Gradientes:  \n",
    "  $$\\frac{\\partial f}{\\partial w_1} = -1 \\times 5 = -5, \\quad \\frac{\\partial f}{\\partial w_2} = -1 \\times 2 = -2$$  \n",
    "- Pesos actualizados:  \n",
    "  $$w_1 = 0 - 0.01 \\times (-5) = 0 + 0.05 = 0.05$$  \n",
    "  $$w_2 = 0 - 0.01 \\times (-2) = 0 + 0.02 = 0.02$$\n",
    "\n",
    "\n",
    "## Iteración 5 (dato 5: $\\mathbf{x}=(6,1)$, $y=1$)\n",
    "\n",
    "- Predicción:  \n",
    "  $$\\hat{y} = 0.05 \\times 6 + 0.02 \\times 1 = 0.3 + 0.02 = 0.32$$  \n",
    "- Error:  \n",
    "  $$e = 0.32 - 1 = -0.68$$  \n",
    "- Pérdida:  \n",
    "  $$f = \\frac{1}{2} \\times (-0.68)^2 = \\frac{1}{2} \\times 0.4624 = 0.2312$$  \n",
    "- Gradientes:  \n",
    "  $$\\frac{\\partial f}{\\partial w_1} = -0.68 \\times 6 = -4.08, \\quad \\frac{\\partial f}{\\partial w_2} = -0.68 \\times 1 = -0.68$$  \n",
    "- Pesos actualizados:  \n",
    "  $$w_1 = 0.05 - 0.01 \\times (-4.08) = 0.05 + 0.0408 = 0.0908$$  \n",
    "  $$w_2 = 0.02 - 0.01 \\times (-0.68) = 0.02 + 0.0068 = 0.0268$$\n",
    "\n",
    "\n",
    "\n",
    "## Iteración 6 (dato 6: $\\mathbf{x}=(7,3)$, $y=1$)\n",
    "\n",
    "- Predicción:  \n",
    "  $$\\hat{y} = 0.0908 \\times 7 + 0.0268 \\times 3 = 0.6356 + 0.0804 = 0.716$$  \n",
    "- Error:  \n",
    "  $$e = 0.716 - 1 = -0.284$$  \n",
    "- Pérdida:  \n",
    "  $$f = \\frac{1}{2} \\times (-0.284)^2 = \\frac{1}{2} \\times 0.0806 = 0.0403$$  \n",
    "- Gradientes:  \n",
    "  $$\\frac{\\partial f}{\\partial w_1} = -0.284 \\times 7 = -1.988$$  \n",
    "  $$\\frac{\\partial f}{\\partial w_2} = -0.284 \\times 3 = -0.852$$  \n",
    "- Pesos actualizados:  \n",
    "  $$w_1 = 0.0908 - 0.01 \\times (-1.988) = 0.0908 + 0.01988 = 0.11068$$  \n",
    "  $$w_2 = 0.0268 - 0.01 \\times (-0.852) = 0.0268 + 0.00852 = 0.03532$$\n",
    "\n",
    "\n",
    "\n",
    "## Resumen final después de una pasada completa\n",
    "\n",
    "- Pesos finales:  \n",
    "  $$\n",
    "  w_1 \\approx 0.1107, \\quad w_2 \\approx 0.0353\n",
    "  $$\n",
    "  \n",
    "- Las pérdidas disminuyeron significativamente a medida que se actualizaban los pesos, y los pesos se movieron en la dirección que reduce el error para la clase 1.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a0bed-d919-46a7-aa35-b52aef28df0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Datos: X = [[x1, x2]], y = etiquetas\n",
    "X = np.array([[1, 2],\n",
    "              [2, 3],\n",
    "              [3, 5],\n",
    "              [5, 2],\n",
    "              [6, 1],\n",
    "              [7, 3]])\n",
    "\n",
    "y = np.array([0, 0, 0, 1, 1, 1])\n",
    "\n",
    "# Parámetros\n",
    "w = np.array([0.0, 0.0])  # pesos iniciales w1, w2\n",
    "eta = 0.01               # tasa de aprendizaje\n",
    "epochs = 20              # número de pasadas completas\n",
    "\n",
    "# Para guardar el error cuadrático medio en cada epoch\n",
    "mse_history = []\n",
    "\n",
    "# Función para calcular predicciones\n",
    "def predict(X, w):\n",
    "    return np.dot(X, w)\n",
    "\n",
    "# Entrenamiento paso a paso, con actualización por muestra (stochastic gradient descent)\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(X)):\n",
    "        y_hat = predict(X[i], w)\n",
    "        error = y_hat - y[i]\n",
    "        grad = error * X[i]\n",
    "        w = w - eta * grad\n",
    "    \n",
    "    # Calcular MSE para todo el conjunto después del epoch\n",
    "    y_preds = predict(X, w)\n",
    "    mse = np.mean((y_preds - y)**2) / 2  # como la función pérdida (1/2)(error)^2\n",
    "    mse_history.append(mse)\n",
    "\n",
    "# Mostrar pesos finales y MSE\n",
    "print(f\"Pesos finales: w1 = {w[0]:.4f}, w2 = {w[1]:.4f}\")\n",
    "print(f\"MSE final: {mse_history[-1]:.4f}\")\n",
    "\n",
    "# --- Gráficas ---\n",
    "\n",
    "# Separar datos por clases para graficar\n",
    "class0 = X[y == 0]\n",
    "class1 = X[y == 1]\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "\n",
    "# Gráfico 1: Datos y frontera de decisión\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(class0[:,0], class0[:,1], color='blue', label='Clase 0')\n",
    "plt.scatter(class1[:,0], class1[:,1], color='red', label='Clase 1')\n",
    "\n",
    "# Línea frontera de decisión: w1*x1 + w2*x2 = 0.5 (umbral 0.5 para clasificación)\n",
    "# Porque la salida es continua, usamos 0.5 como punto de corte para clasificar\n",
    "x_vals = np.linspace(0, 8, 100)\n",
    "if abs(w[1]) > 1e-6:\n",
    "    y_vals = (0.5 - w[0]*x_vals) / w[1]\n",
    "    plt.plot(x_vals, y_vals, 'g--', label='Frontera de decisión')\n",
    "else:\n",
    "    plt.axvline(x=0.5/w[0], color='g', linestyle='--', label='Frontera de decisión')\n",
    "\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.title('Datos y Frontera de Decisión del Perceptrón')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 8)\n",
    "plt.ylim(0, 6)\n",
    "\n",
    "# Gráfico 2: Evolución del error cuadrático medio (MSE)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(range(1, epochs+1), mse_history, marker='o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error cuadrático medio (MSE)')\n",
    "plt.title('Evolución del MSE durante el entrenamiento')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6b4b2-2e1f-45ba-9c92-de944fe7e4d4",
   "metadata": {},
   "source": [
    "# Introducción a las Redes Neuronales\n",
    "\n",
    "Las redes neuronales artificiales (RNA) son modelos computacionales inspirados en la estructura y funcionamiento del cerebro humano. Están diseñadas para reconocer patrones y relaciones en los datos mediante un proceso de aprendizaje automático.\n",
    "\n",
    "Una red neuronal está compuesta por unidades básicas llamadas **neuronas** o **nodos**, que se organizan en capas. Cada neurona recibe una entrada, la procesa y envía una salida a las neuronas de la siguiente capa.\n",
    "\n",
    "## Elementos básicos de una red neuronal\n",
    "\n",
    "* **Entradas o características**: Son los datos de entrada que alimentan la red. Por ejemplo, píxeles de una imagen, valores numéricos de sensores, o características extraídas de texto.\n",
    "\n",
    "* **Pesos $w_i$, con $i = 1, \\ldots, m$**: Son coeficientes que multiplican cada entrada para indicar su importancia relativa. Estos pesos se ajustan durante el entrenamiento para minimizar el error de la red.\n",
    "\n",
    "* **Bias o sesgo $b$**: Es un término adicional que permite a la neurona desplazar la función de activación, lo que ayuda a la red a aprender patrones más complejos y evita que la salida sea siempre cero cuando las entradas son cero.\n",
    "\n",
    "* **Suma ponderada $z$**: La neurona calcula la suma ponderada de las entradas y el sesgo, dada por\n",
    "  $$\n",
    "  z = \\sum_{i=1}^m w_i x_i + b.\n",
    "  $$\n",
    "\n",
    "* **Función de activación $f(z)$**: Esta función introduce no linealidad en el modelo y decide la salida final de la neurona a partir de la suma ponderada. Sin la función de activación, la red solo podría modelar relaciones lineales.\n",
    "\n",
    "* **Salida**: El resultado de aplicar la función de activación a $z$ que puede ser una señal binaria, un valor continuo o categórico, dependiendo del problema.\n",
    "\n",
    "## ¿Por qué las funciones de activación son importantes?\n",
    "\n",
    "Las funciones de activación permiten que las redes neuronales aprendan y modelen relaciones no lineales en los datos. Sin ellas, una red profunda con múltiples capas se reduciría a una función lineal simple, sin poder capturar patrones complejos.\n",
    "\n",
    "Las funciones no lineales más comunes incluyen:\n",
    "\n",
    "* **ReLU (Rectified Linear Unit)**: $$ f(z) = \\max(0, z) $$\n",
    "  \n",
    "  Es simple y eficiente para redes profundas, ayudando a evitar el problema del gradiente desvanecido.\n",
    "\n",
    "* **Sigmoide**: $$ f(z) = \\frac{1}{1 + e^{-z}} $$\n",
    "  \n",
    "  Su salida está entre 0 y 1, útil para problemas de clasificación binaria.\n",
    "\n",
    "* **Tangente hiperbólica (tanh)**: $$ f(z) = \\tanh(z) = \\frac{e^{z} - e^{-z}}{e^{z} + e^{-z}} $$\n",
    "  \n",
    "  Produce salidas entre -1 y 1, centrándose en cero, lo que puede acelerar el aprendizaje.\n",
    "\n",
    "* **Función escalón (step function)**: $$ f(z) = \\begin{cases} 1, & z > 0 \\\\ 0, & z \\leq 0 \\end{cases} $$\n",
    "\n",
    "  Aunque sencilla, no es diferenciable, lo que limita su uso en métodos basados en gradientes.\n",
    "\n",
    "## Arquitectura de una red neuronal\n",
    "\n",
    "Las redes neuronales se componen típicamente de las siguientes capas:\n",
    "\n",
    "* **Capa de entrada**: Recibe las características originales.\n",
    "\n",
    "* **Capas ocultas**: Realizan transformaciones intermedias mediante neuronas con funciones de activación. Pueden ser una o varias.\n",
    "\n",
    "* **Capa de salida**: Produce el resultado final, que puede ser una clase, un valor numérico, o una distribución de probabilidades.\n",
    "\n",
    "## Proceso de aprendizaje\n",
    "\n",
    "El entrenamiento de una red neuronal consiste en ajustar los pesos y sesgos para minimizar la diferencia entre la salida predicha y la salida real (etiquetas o valores esperados). Este proceso se realiza mediante algoritmos de optimización como el **gradiente descendente** y la retropropagación del error.\n",
    "\n",
    "Este aprendizaje permite que la red generalice y haga predicciones en datos no vistos previamente.\n",
    "\n",
    "\n",
    "\n",
    "Las redes neuronales son la base de muchas técnicas modernas de inteligencia artificial, incluyendo reconocimiento de imágenes, procesamiento de lenguaje natural, y juegos.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca649fb-8f40-4da8-909a-3b6034d209dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Funciones de activación\n",
    "\n",
    "def f1(z):\n",
    "    return 1 if z > 0 else 0\n",
    "\n",
    "def f2(z):\n",
    "    if z > 0:\n",
    "        return 1\n",
    "    elif z < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def f3(z):\n",
    "    return z\n",
    "\n",
    "def f4(z):\n",
    "    return z if z > 0 else 0\n",
    "\n",
    "def f5(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def f6(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "z = np.linspace(-5, 5, 400)\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax1.plot(z, [f1(i) for i in z], label='f1: Escalón binario', color='blue')\n",
    "ax1.axhline(0, color='black', linewidth=0.8)\n",
    "ax1.axvline(0, color='black', linewidth=0.8)\n",
    "ax1.set_title('f(z) = 0 si z ≤ 0, f(z) = 1 si z > 0')\n",
    "ax1.set_xlabel('z')\n",
    "ax1.set_ylabel('f(z)')\n",
    "ax1.set_ylim(-0.2, 1.2)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(z, [f2(i) for i in z], label='f2: Función signo', color='green')\n",
    "ax2.axhline(0, color='black', linewidth=0.8)\n",
    "ax2.axvline(0, color='black', linewidth=0.8)\n",
    "ax2.set_title('f(z) = -1 si z < 0, 0 si z = 0, 1 si z > 0')\n",
    "ax2.set_xlabel('z')\n",
    "ax2.set_ylim(-1.2, 1.2)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax1.plot(z, [f3(i) for i in z], label='f3: Identidad', color='purple')\n",
    "ax1.axhline(0, color='black', linewidth=0.8)\n",
    "ax1.axvline(0, color='black', linewidth=0.8)\n",
    "ax1.set_title('f(z) = z')\n",
    "ax1.set_xlabel('z')\n",
    "ax1.set_ylabel('f(z)')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(z, [f4(i) for i in z], label='f4: ReLU', color='orange')\n",
    "ax2.axhline(0, color='black', linewidth=0.8)\n",
    "ax2.axvline(0, color='black', linewidth=0.8)\n",
    "ax2.set_title('f(z) = max(0, z)')\n",
    "ax2.set_xlabel('z')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax1.plot(z, [f5(i) for i in z], label='f5: Tangente hiperbólica (tanh)', color='red')\n",
    "ax1.axhline(0, color='black', linewidth=0.8)\n",
    "ax1.axvline(0, color='black', linewidth=0.8)\n",
    "ax1.set_title('f(z) = tanh(z)')\n",
    "ax1.set_xlabel('z')\n",
    "ax1.set_ylabel('f(z)')\n",
    "ax1.set_ylim(-1.1, 1.1)\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(z, [f6(i) for i in z], label='f6: Sigmoide', color='brown')\n",
    "ax2.axhline(0, color='black', linewidth=0.8)\n",
    "ax2.axvline(0, color='black', linewidth=0.8)\n",
    "ax2.set_title('f(z) = 1 / (1 + e^{-z})')\n",
    "ax2.set_xlabel('z')\n",
    "ax2.set_ylim(-0.1, 1.1)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31d370-89e5-470e-bd26-7e95e251e964",
   "metadata": {},
   "source": [
    "##  Derivación de la Regla de Actualización de Pesos Usando Taylor y Gradiente Descendente\n",
    "\n",
    "El **gradiente descendente** es una técnica que permite **minimizar** una función objetivo (por ejemplo, la función de costo de una red neuronal). Para entender su justificación matemática, partimos de la **expansión de Taylor de primer orden**.\n",
    "\n",
    "\n",
    "\n",
    "###  Expansión de Taylor de Primer Orden\n",
    "\n",
    "Sea $J(w)$ una función escalar de varias variables (los pesos de la red), y sea $w_0$ el valor actual de los pesos. La expansión de Taylor en torno a $w_0$ es:\n",
    "\n",
    "$$\n",
    "J(w) \\approx J(w_0) + \\nabla J(w_0)^T (w - w_0)\n",
    "$$\n",
    "\n",
    "donde:\n",
    "- $J(w_0)$ es el valor de la función en el punto actual.\n",
    "- $\\nabla J(w_0)$ es el gradiente evaluado en $w_0$.\n",
    "- $(w - w_0)$ es el desplazamiento desde el punto actual.\n",
    "\n",
    "Esta expansión nos dice cómo cambia $J(w)$ cuando los pesos cambian ligeramente desde $w_0$.\n",
    "\n",
    "\n",
    "\n",
    "### ¿Cómo minimizar localmente $J(w)$?\n",
    "\n",
    "Queremos **elegir un nuevo valor de pesos $w$** que haga que $J(w)$ sea lo más pequeño posible.\n",
    "\n",
    "La derivación de Taylor sugiere que para que $J(w)$ disminuya, el producto escalar $\\nabla J(w_0)^T (w - w_0)$ debe ser negativo.\n",
    "\n",
    "Una forma simple y efectiva de garantizar esto es moverse **en la dirección opuesta al gradiente**:\n",
    "\n",
    "$$\n",
    "w = w_0 - \\eta \\cdot \\nabla J(w_0)\n",
    "$$\n",
    "\n",
    "donde $\\eta > 0$ es un **parámetro pequeño** llamado *tasa de aprendizaje*. Este paso garantiza que $J(w)$ disminuya en cada iteración, si $\\eta$ es suficientemente pequeño.\n",
    "\n",
    "\n",
    "\n",
    "###  Regla General de Gradiente Descendente\n",
    "\n",
    "A partir de esta idea, obtenemos la regla de actualización estándar del **gradiente descendente**:\n",
    "\n",
    "$$\n",
    "w^{(t+1)} = w^{(t)} - \\eta \\cdot \\nabla J(w^{(t)})\n",
    "$$\n",
    "\n",
    "donde:\n",
    "- $w^{(t)}$ es el vector de pesos en la iteración $t$.\n",
    "- $\\eta$ es la tasa de aprendizaje.\n",
    "- $\\nabla J(w^{(t)})$ es el gradiente de la función de costo con respecto a los pesos.\n",
    "\n",
    "\n",
    "\n",
    "### Interpretación Geométrica\n",
    "\n",
    "- El **gradiente** $\\nabla J(w)$ apunta en la dirección de máximo incremento de $J$.\n",
    "- Movernos en la **dirección opuesta al gradiente** reduce $J$.\n",
    "- La tasa de aprendizaje $\\eta$ controla **qué tan grande es el paso** que damos en cada iteración.\n",
    "\n",
    "\n",
    "El algoritmo de **gradiente descendente** se deriva directamente de la **expansión de Taylor** de primer orden. La actualización de los pesos es una forma de aproximar el mínimo de la función de costo al moverse en la dirección de más rápido descenso.\n",
    "\n",
    "Este fundamento es lo que permite a las redes neuronales aprender ajustando sus pesos en función de los errores cometidos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7de7d7-c24f-4511-828d-7c79010e37bb",
   "metadata": {},
   "source": [
    "## Ejemplo: Uso del Gradiente Descendente para Minimizar una Función Cuadrática\n",
    "\n",
    "Para ilustrar cómo funciona el gradiente descendente, vamos a usar una función simple:\n",
    "\n",
    "$$\n",
    "J(w) = (w - 3)^2\n",
    "$$\n",
    "\n",
    "Esta es una parábola que tiene su mínimo en $w = 3$, donde $J(w) = 0$.\n",
    "\n",
    "\n",
    "###  Paso 1: Derivada de la función\n",
    "\n",
    "El gradiente de $J(w)$ con respecto a $w$ es simplemente su derivada:\n",
    "\n",
    "$$\n",
    "\\frac{dJ}{dw} = 2(w - 3)\n",
    "$$\n",
    "\n",
    "Este valor nos dice **en qué dirección y con qué magnitud debemos ajustar $w$** para que $J(w)$ disminuya.\n",
    "\n",
    "\n",
    "\n",
    "### Paso 2: Regla de actualización del gradiente descendente\n",
    "\n",
    "Usamos la regla general:\n",
    "\n",
    "$$\n",
    "w_{\\text{new}} = w_{\\text{old}} - \\eta \\cdot \\frac{dJ}{dw}\n",
    "$$\n",
    "\n",
    "donde $\\eta$ es la *tasa de aprendizaje*, que controla el tamaño del paso.\n",
    "\n",
    "###  Paso 3: Ejecución paso a paso\n",
    "\n",
    "Supongamos que:\n",
    "\n",
    "- Valor inicial: $w = 0$\n",
    "- Tasa de aprendizaje: $\\eta = 0.1$\n",
    "\n",
    "Entonces en cada iteración calculamos:\n",
    "\n",
    "1. $\\frac{dJ}{dw} = 2(w - 3)$  \n",
    "2. $w_{\\text{new}} = w - 0.1 \\cdot 2(w - 3)$  \n",
    "3. Repetimos hasta que $w$ esté suficientemente cerca de 3.\n",
    "\n",
    "\n",
    "\n",
    "###  Iteraciones \n",
    "\n",
    "| Iteración |     $w$     | $\\frac{dJ}{dw}$ |    $J(w)$     |\n",
    "|:---------:|:-----------:|:---------------:|:-------------:|\n",
    "|     0     |     0.0     |      -6.0       |     9.0       |\n",
    "|     1     |     0.6     |      -4.8       |     5.76      |\n",
    "|     2     |    1.08     |      -3.84      |    3.6864     |\n",
    "|     3     |   1.464     |     -3.072      |    2.3593     |\n",
    "|     4     |  1.7712     |     -2.4576     |    1.5099     |\n",
    "|   ...     |     ...     |       ...       |      ...      |\n",
    "\n",
    "Como puedes ver, el valor de $w$ se **acerca cada vez más a 3**, y la función $J(w)$ disminuye progresivamente.\n",
    "\n",
    "\n",
    "\n",
    "Este ejemplo muestra cómo el **gradiente descendente ajusta los valores de los parámetros** para minimizar la función de costo. En problemas reales de redes neuronales:\n",
    "\n",
    "- La función $J$ representa el error (como MSE o cross-entropy),\n",
    "- Los parámetros $w$ son los pesos de la red,\n",
    "- El gradiente se calcula con derivadas parciales respecto a cada peso,\n",
    "- Y se usa esta misma lógica para actualizar todos los pesos de la red en cada iteración.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd2e7f3-5626-447c-b947-d978ff17295b",
   "metadata": {},
   "source": [
    "## Métricas comunes para evaluar redes neuronales\n",
    "\n",
    "Las métricas nos ayudan a **evaluar el rendimiento** de una red neuronal, tanto durante el entrenamiento como al final del mismo, para saber si el modelo está aprendiendo correctamente o necesita ajustes.\n",
    "\n",
    "### 1. Funciones de pérdida vs métricas\n",
    "\n",
    "- **Función de pérdida (Loss):** Es la función que se **minimiza durante el entrenamiento** (por ejemplo, `cross-entropy` o `mean squared error`).\n",
    "- **Métricas:** Son **valores informativos** que permiten evaluar el rendimiento del modelo desde una perspectiva más interpretativa (por ejemplo, `accuracy`, `precision`, etc.).\n",
    "\n",
    "\n",
    "\n",
    "## Clasificación\n",
    "\n",
    "### 1. Accuracy (Precisión global)\n",
    "\n",
    "Proporción de predicciones correctas.\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{Número de predicciones correctas}}{\\text{Total de predicciones}}\n",
    "$$\n",
    "\n",
    "\n",
    "### 2. Precision\n",
    "\n",
    "De las predicciones positivas que hizo el modelo, ¿cuántas fueron realmente positivas?\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- TP: Verdaderos Positivos  \n",
    "- FP: Falsos Positivos\n",
    "\n",
    "\n",
    "\n",
    "### 3. Recall (Sensibilidad o Tasa de Verdaderos Positivos)\n",
    "\n",
    "De los elementos realmente positivos, ¿cuántos fueron correctamente identificados?\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### 4. F1-Score\n",
    "\n",
    "Es la media armónica entre precisión y recall. Útil cuando hay clases desbalanceadas.\n",
    "\n",
    "$$\n",
    "F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### 5. Log-Loss o Cross-Entropy\n",
    "\n",
    "Mide la distancia entre las probabilidades predichas y las verdaderas clases (es también una función de pérdida):\n",
    "\n",
    "$$\n",
    "\\text{Cross-Entropy} = - \\sum_{i} y_i \\log(p_i)\n",
    "$$\n",
    "\n",
    "Donde $y_i$ es la clase real (0 o 1) y $p_i$ es la probabilidad predicha.\n",
    "\n",
    "\n",
    "\n",
    "## Regresión\n",
    "\n",
    "###  1. Mean Squared Error (MSE)\n",
    "\n",
    "Promedio del cuadrado de los errores.\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "###  2. Root Mean Squared Error (RMSE)\n",
    "\n",
    "Raíz cuadrada del MSE. Tiene las mismas unidades que las predicciones.\n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\text{MSE}}\n",
    "$$\n",
    "\n",
    "\n",
    "###  3. Mean Absolute Error (MAE)\n",
    "\n",
    "Promedio del valor absoluto de los errores.\n",
    "\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "### 4. Coeficiente de Determinación ($R^2$)\n",
    "\n",
    "Mide qué tan bien se ajusta el modelo a los datos (1 es perfecto, 0 es aleatorio):\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n",
    "$$\n",
    "\n",
    "\n",
    "## ¿Qué métrica elegir?\n",
    "\n",
    "- **Clasificación balanceada:** Accuracy.\n",
    "- **Clasificación desbalanceada:** F1, Precision, Recall.\n",
    "- **Regresión con grandes errores penalizados:** MSE o RMSE.\n",
    "- **Regresión con tolerancia a grandes errores:** MAE.\n",
    "\n",
    "\n",
    "\n",
    "Estas métricas se pueden monitorear durante el entrenamiento usando frameworks como TensorFlow/Keras o PyTorch, y te ayudan a ajustar hiperparámetros, detectar sobreajuste y evaluar modelos en producción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d5b319-2f95-456b-bc49-f5e93aaa2e30",
   "metadata": {},
   "source": [
    "## Evaluación del modelo usando métricas de regresión\n",
    "\n",
    "Después de entrenar nuestro modelo usando gradiente descendente para ajustar una recta $y = wx + b$, podemos evaluar su rendimiento con las siguientes métricas:\n",
    "\n",
    "\n",
    "### 1. **Mean Absolute Error (MAE)**\n",
    "\n",
    "Mide el **promedio de los errores absolutos**:\n",
    "\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum |y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "Interpretación: En promedio, el modelo se equivoca en X unidades.\n",
    "\n",
    "\n",
    "\n",
    "### 2. **Mean Squared Error (MSE)**\n",
    "\n",
    "Promedia los **errores al cuadrado**, penalizando más los errores grandes:\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "\n",
    "### 3. **Root Mean Squared Error (RMSE)**\n",
    "\n",
    "Es la **raíz cuadrada del MSE**, lo que da una métrica con las **mismas unidades que la salida**:\n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\text{MSE}}\n",
    "$$\n",
    "\n",
    "\n",
    "### 4. **Coeficiente de Determinación ($R^2$ Score)**\n",
    "\n",
    "Indica **qué tan bien el modelo explica la variabilidad** de los datos. Un valor de $R^2 = 1$ es perfecto, y $R^2 = 0$ indica que el modelo es tan bueno como adivinar el promedio:\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n",
    "$$\n",
    "\n",
    "\n",
    "Estas métricas permiten evaluar si el modelo entrenado realmente está haciendo buenas predicciones y se acercan a la verdad del problema de regresión.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8cf69a-c57f-4310-a4f7-d619b3f10394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Simulamos datos reales con algo de ruido\n",
    "np.random.seed(0)\n",
    "x = np.linspace(0, 10, 50)\n",
    "y_true = 3 * x + 7 + np.random.normal(0, 2, size=x.shape)\n",
    "\n",
    "# Inicializamos los pesos\n",
    "w = 0.0\n",
    "b = 0.0\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "# Entrenamiento con gradiente descendente\n",
    "for epoch in range(epochs):\n",
    "    y_pred = w * x + b\n",
    "    error = y_pred - y_true\n",
    "    dw = (2 / len(x)) * np.dot(error, x)\n",
    "    db = (2 / len(x)) * np.sum(error)\n",
    "    w -= learning_rate * dw\n",
    "    b -= learning_rate * db\n",
    "\n",
    "# Predicciones finales\n",
    "y_pred_final = w * x + b\n",
    "\n",
    "#  Mostrar el ajuste\n",
    "plt.scatter(x, y_true, label='Datos reales')\n",
    "plt.plot(x, y_pred_final, color='red', label='Modelo ajustado')\n",
    "plt.legend()\n",
    "plt.title(\"Ajuste de recta con gradiente descendente\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Métricas de evaluación\n",
    "mae = mean_absolute_error(y_true, y_pred_final)\n",
    "mse = mean_squared_error(y_true, y_pred_final)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_true, y_pred_final)\n",
    "\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"MSE:  {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R²:   {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1439af4b-12b2-453e-8733-7346acb6fcd8",
   "metadata": {},
   "source": [
    "# Ejemplo clasificación binaria con redes neuronales \n",
    "\n",
    "En este ejemplo, construimos una red neuronal **de una sola neurona** con activación sigmoide para resolver un problema de clasificación binaria.\n",
    "\n",
    "\n",
    "### 1. **Modelo**\n",
    "\n",
    "Una red neuronal con una capa de salida sigmoide modela la probabilidad de que una entrada $x$ pertenezca a la clase 1:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\sigma(w^\\top x + b)\n",
    "$$\n",
    "\n",
    "donde $\\sigma(z) = \\frac{1}{1 + e^{-z}}$ es la función sigmoide.\n",
    "\n",
    "### 2. **Pérdida (Binary Cross Entropy)**\n",
    "\n",
    "La función de costo para clasificación binaria es:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = - \\frac{1}{N} \\sum_{i=1}^N \\left[ y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i) \\right]\n",
    "$$\n",
    "\n",
    "### 3. **Actualización por Gradiente Descendente**\n",
    "\n",
    "Los pesos se actualizan usando:\n",
    "\n",
    "$$\n",
    "w := w - \\eta \\cdot \\frac{\\partial \\mathcal{L}}{\\partial w}\n",
    "\\quad\\quad\n",
    "b := b - \\eta \\cdot \\frac{\\partial \\mathcal{L}}{\\partial b}\n",
    "$$\n",
    "\n",
    "\n",
    "##  Métricas de evaluación\n",
    "\n",
    "Dado el resultado de la red, evaluamos el rendimiento usando las siguientes métricas:\n",
    "\n",
    "- **Accuracy**: proporción de clasificaciones correctas:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "- **Precision**: entre todas las predicciones positivas, cuántas eran correctas:\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "- **Recall**: de todos los positivos reales, cuántos fueron predichos como positivos:\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "### F1 Score (Puntaje F1)\n",
    "\n",
    "El **F1 Score** es una métrica que combina la precisión y el recall en un solo valor, ofreciendo un balance entre ambos. Se define como la **media armónica** entre la precisión y el recall:\n",
    "\n",
    "$$\n",
    "\\text{F1} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "\n",
    "El F1 Score es útil porque:\n",
    "\n",
    "- Da un único valor que refleja tanto la precisión como el recall, ideal cuando se quiere un equilibrio entre ambos.\n",
    "- Penaliza fuertemente los casos donde uno de los dos valores (precisión o recall) es muy bajo.\n",
    "- Es especialmente importante en problemas donde existe un desbalance de clases, o donde tanto los falsos positivos como los falsos negativos tienen consecuencias importantes.\n",
    "\n",
    "\n",
    "- Un F1 Score cercano a 1 indica que el modelo tiene tanto alta precisión como alto recall.\n",
    "- Un F1 Score cercano a 0 indica que el modelo tiene baja precisión, bajo recall o ambos.\n",
    "\n",
    "- **Matriz de confusión**:\n",
    "\n",
    "La matriz de confusión es una tabla que permite evaluar el desempeño de un modelo de clasificación mostrando cómo se distribuyen las predicciones en relación con las clases reales. En un problema binario (dos clases), la matriz tiene la siguiente estructura:\n",
    "\n",
    "|                  | Predicción Positiva (Clase 1) | Predicción Negativa (Clase 0) |\n",
    "|------------------|-------------------------------|-------------------------------|\n",
    "| **Clase Real 1** | Verdaderos Positivos (TP)      | Falsos Negativos (FN)          |\n",
    "| **Clase Real 0** | Falsos Positivos (FP)          | Verdaderos Negativos (TN)      |\n",
    "\n",
    "#### Definiciones:\n",
    "\n",
    "- **Verdaderos Positivos (TP):** Casos donde el modelo predijo la clase positiva correctamente.  \n",
    "  Ejemplo: El dato pertenece a la clase 1 y el modelo también predijo clase 1.\n",
    "\n",
    "- **Falsos Positivos (FP):** Casos donde el modelo predijo la clase positiva incorrectamente.  \n",
    "  Ejemplo: El dato pertenece a la clase 0, pero el modelo predijo clase 1 (error tipo I).\n",
    "\n",
    "- **Verdaderos Negativos (TN):** Casos donde el modelo predijo la clase negativa correctamente.  \n",
    "  Ejemplo: El dato pertenece a la clase 0 y el modelo predijo clase 0.\n",
    "\n",
    "- **Falsos Negativos (FN):** Casos donde el modelo predijo la clase negativa incorrectamente.  \n",
    "  Ejemplo: El dato pertenece a la clase 1, pero el modelo predijo clase 0 (error tipo II).\n",
    "\n",
    "\n",
    "La matriz de confusión nos permite entender mejor los errores que comete el modelo y no solo la precisión global. Por ejemplo:\n",
    "\n",
    "- Un modelo con alta precisión puede tener muchos falsos negativos, lo que puede ser grave en aplicaciones como detección de enfermedades.\n",
    "- Analizando FP y FN podemos decidir ajustar el umbral de decisión o balancear el modelo según la prioridad de cada tipo de error.\n",
    "\n",
    "### Ejemplo sencillo\n",
    "\n",
    "Supongamos que tenemos 100 datos, con 50 de cada clase. El modelo predijo así:\n",
    "\n",
    "|                  | Predicción Positiva | Predicción Negativa |\n",
    "|------------------|---------------------|---------------------|\n",
    "| **Clase Real 1** | 45 (TP)             | 5 (FN)              |\n",
    "| **Clase Real 0** | 3 (FP)              | 47 (TN)             |\n",
    "\n",
    "Esto significa que:\n",
    "\n",
    "- El modelo acertó en 45 casos positivos y 47 negativos.\n",
    "- Cometió 3 errores clasificando negativos como positivos (FP).\n",
    "- Cometió 5 errores clasificando positivos como negativos (FN).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e43fe-ad1e-44a8-886a-d589004c427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dataset artificial 2D (dos clases linealmente separables)\n",
    "np.random.seed(0)\n",
    "N = 100\n",
    "X1 = np.random.randn(N, 2) + np.array([2, 2])   # Clase 1\n",
    "X0 = np.random.randn(N, 2) + np.array([-2, -2]) # Clase 0\n",
    "X = np.vstack([X1, X0])\n",
    "y = np.array([1]*N + [0]*N).reshape(-1, 1)      # etiquetas\n",
    "\n",
    "# Función sigmoide\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Inicialización de pesos y bias\n",
    "W = np.random.randn(2, 1)\n",
    "b = 0\n",
    "lr = 0.1  # tasa de aprendizaje\n",
    "epochs = 7\n",
    "\n",
    "losses = []\n",
    "\n",
    "# Entrenamiento por gradiente descendente\n",
    "for epoch in range(epochs):\n",
    "    z = X @ W + b\n",
    "    y_pred = sigmoid(z)\n",
    "    loss = -np.mean(y * np.log(y_pred + 1e-8) + (1 - y) * np.log(1 - y_pred + 1e-8))\n",
    "    losses.append(loss)\n",
    "\n",
    "    # Gradientes\n",
    "    dz = y_pred - y\n",
    "    dW = X.T @ dz / len(X)\n",
    "    db = np.mean(dz)\n",
    "\n",
    "    # Actualización\n",
    "    W -= lr * dW\n",
    "    b -= lr * db\n",
    "\n",
    "    if epoch % 200 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss:.4f}\")\n",
    "\n",
    "# Predicciones finales (umbral 0.5)\n",
    "y_pred_class = (sigmoid(X @ W + b) >= 0.5).astype(int)\n",
    "\n",
    "# Métricas\n",
    "TP = np.sum((y_pred_class == 1) & (y == 1))\n",
    "TN = np.sum((y_pred_class == 0) & (y == 0))\n",
    "FP = np.sum((y_pred_class == 1) & (y == 0))\n",
    "FN = np.sum((y_pred_class == 0) & (y == 1))\n",
    "\n",
    "accuracy = (TP + TN) / len(y)\n",
    "precision = TP / (TP + FP + 1e-8)\n",
    "recall = TP / (TP + FN + 1e-8)\n",
    "f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "\n",
    "print(\"\\n--- Métricas ---\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Matriz de Confusión:\\n[[TN={TN}, FP={FP}]\\n [FN={FN}, TP={TP}]]\")\n",
    "\n",
    "# --- Gráfica de la convergencia ---\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(losses, label='Loss (Binary Cross-Entropy)')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Convergencia del entrenamiento')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# --- Gráfica de datos y frontera de decisión ---\n",
    "\n",
    "# Crear malla para frontera\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
    "                     np.linspace(y_min, y_max, 300))\n",
    "\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "probs = sigmoid(grid @ W + b).reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "# Dibujar la frontera de decisión (prob = 0.5)\n",
    "contour = plt.contourf(xx, yy, probs, levels=[0,0.5,1], alpha=0.3, colors=['blue', 'red'])\n",
    "plt.colorbar(contour)\n",
    "\n",
    "# Graficar puntos de datos\n",
    "plt.scatter(X1[:, 0], X1[:, 1], c='red', label='Clase 1')\n",
    "plt.scatter(X0[:, 0], X0[:, 1], c='blue', label='Clase 0')\n",
    "\n",
    "plt.title('Datos y frontera de decisión de la red neuronal')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703ebd4-5c74-44bd-84d7-a418e99c61c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
